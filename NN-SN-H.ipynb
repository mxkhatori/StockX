{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc10fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bab103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\49173\\Desktop\\Data\\stockxf2.csv\")\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4290272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>orderDate</th>\n",
       "      <th>salePrice</th>\n",
       "      <th>shoeSize</th>\n",
       "      <th>brand</th>\n",
       "      <th>sneakerName</th>\n",
       "      <th>colorway</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>salesThisPeriod</th>\n",
       "      <th>hype</th>\n",
       "      <th>days</th>\n",
       "      <th>collaboration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55a9ccfe-129a-438a-9989-b877c2a66279</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>300</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>White/Black-Neutral Grey</td>\n",
       "      <td>210</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2476</td>\n",
       "      <td>10743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55a9ccfe-129a-438a-9989-b877c2a66279</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>300</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>White/Black-Neutral Grey</td>\n",
       "      <td>210</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2476</td>\n",
       "      <td>10743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55a9ccfe-129a-438a-9989-b877c2a66279</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>382</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>White/Black-Neutral Grey</td>\n",
       "      <td>210</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2476</td>\n",
       "      <td>10743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55a9ccfe-129a-438a-9989-b877c2a66279</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>304</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>White/Black-Neutral Grey</td>\n",
       "      <td>210</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2476</td>\n",
       "      <td>10743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55a9ccfe-129a-438a-9989-b877c2a66279</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>390</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>White/Black-Neutral Grey</td>\n",
       "      <td>210</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>2476</td>\n",
       "      <td>10743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192880</th>\n",
       "      <td>3774e829-99f4-46d6-bb94-f9e19ad55ad3</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>384</td>\n",
       "      <td>10.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>Sesame/Sesame/Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>13</td>\n",
       "      <td>5366</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192881</th>\n",
       "      <td>3774e829-99f4-46d6-bb94-f9e19ad55ad3</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>366</td>\n",
       "      <td>12.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>Sesame/Sesame/Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>13</td>\n",
       "      <td>5366</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882</th>\n",
       "      <td>3774e829-99f4-46d6-bb94-f9e19ad55ad3</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>420</td>\n",
       "      <td>10.5</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>Sesame/Sesame/Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>13</td>\n",
       "      <td>5366</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192883</th>\n",
       "      <td>3774e829-99f4-46d6-bb94-f9e19ad55ad3</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>357</td>\n",
       "      <td>11.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>Sesame/Sesame/Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>13</td>\n",
       "      <td>5366</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192884</th>\n",
       "      <td>3774e829-99f4-46d6-bb94-f9e19ad55ad3</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>383</td>\n",
       "      <td>9.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>Sesame/Sesame/Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>13</td>\n",
       "      <td>5366</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192885 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   productId   orderDate  salePrice  shoeSize  \\\n",
       "0       55a9ccfe-129a-438a-9989-b877c2a66279  2022-05-26        300       9.5   \n",
       "1       55a9ccfe-129a-438a-9989-b877c2a66279  2022-05-26        300       9.0   \n",
       "2       55a9ccfe-129a-438a-9989-b877c2a66279  2022-05-26        382      10.0   \n",
       "3       55a9ccfe-129a-438a-9989-b877c2a66279  2022-05-26        304       8.0   \n",
       "4       55a9ccfe-129a-438a-9989-b877c2a66279  2022-05-26        390      12.0   \n",
       "...                                      ...         ...        ...       ...   \n",
       "192880  3774e829-99f4-46d6-bb94-f9e19ad55ad3  2022-03-18        384      10.0   \n",
       "192881  3774e829-99f4-46d6-bb94-f9e19ad55ad3  2022-03-18        366      12.0   \n",
       "192882  3774e829-99f4-46d6-bb94-f9e19ad55ad3  2022-03-18        420      10.5   \n",
       "192883  3774e829-99f4-46d6-bb94-f9e19ad55ad3  2022-03-18        357      11.0   \n",
       "192884  3774e829-99f4-46d6-bb94-f9e19ad55ad3  2022-03-18        383       9.0   \n",
       "\n",
       "         brand                       sneakerName                  colorway  \\\n",
       "0       Jordan     Jordan 4 Retro Military Black  White/Black-Neutral Grey   \n",
       "1       Jordan     Jordan 4 Retro Military Black  White/Black-Neutral Grey   \n",
       "2       Jordan     Jordan 4 Retro Military Black  White/Black-Neutral Grey   \n",
       "3       Jordan     Jordan 4 Retro Military Black  White/Black-Neutral Grey   \n",
       "4       Jordan     Jordan 4 Retro Military Black  White/Black-Neutral Grey   \n",
       "...        ...                               ...                       ...   \n",
       "192880  adidas  adidas Yeezy Boost 350 V2 Sesame      Sesame/Sesame/Sesame   \n",
       "192881  adidas  adidas Yeezy Boost 350 V2 Sesame      Sesame/Sesame/Sesame   \n",
       "192882  adidas  adidas Yeezy Boost 350 V2 Sesame      Sesame/Sesame/Sesame   \n",
       "192883  adidas  adidas Yeezy Boost 350 V2 Sesame      Sesame/Sesame/Sesame   \n",
       "192884  adidas  adidas Yeezy Boost 350 V2 Sesame      Sesame/Sesame/Sesame   \n",
       "\n",
       "        retailPrice releaseDate  salesThisPeriod   hype  days  collaboration  \n",
       "0               210  2022-05-21             2476  10743     5              1  \n",
       "1               210  2022-05-21             2476  10743     5              1  \n",
       "2               210  2022-05-21             2476  10743     5              1  \n",
       "3               210  2022-05-21             2476  10743     5              1  \n",
       "4               210  2022-05-21             2476  10743     5              1  \n",
       "...             ...         ...              ...    ...   ...            ...  \n",
       "192880          220  2018-11-23               13   5366  1211              1  \n",
       "192881          220  2018-11-23               13   5366  1211              1  \n",
       "192882          220  2018-11-23               13   5366  1211              1  \n",
       "192883          220  2018-11-23               13   5366  1211              1  \n",
       "192884          220  2018-11-23               13   5366  1211              1  \n",
       "\n",
       "[192885 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56742a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_hype'] = np.log(df['hype']+1)\n",
    "df['log_resalePrice'] = np.log(df['salePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a609b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['productId', \n",
    "              'orderDate',\n",
    "              #'sneakerName',\n",
    "              'colorway', \n",
    "              'releaseDate', \n",
    "              \"hype\", \n",
    "              'salePrice'],\n",
    "              axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44273c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoeSize</th>\n",
       "      <th>brand</th>\n",
       "      <th>sneakerName</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>salesThisPeriod</th>\n",
       "      <th>days</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>log_hype</th>\n",
       "      <th>log_resalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.5</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.945421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.717028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>Jordan 4 Retro Military Black</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.966147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192880</th>\n",
       "      <td>10.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.950643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192881</th>\n",
       "      <td>12.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.902633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882</th>\n",
       "      <td>10.5</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>6.040255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192883</th>\n",
       "      <td>11.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.877736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192884</th>\n",
       "      <td>9.0</td>\n",
       "      <td>adidas</td>\n",
       "      <td>adidas Yeezy Boost 350 V2 Sesame</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.948035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192885 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shoeSize   brand                       sneakerName  retailPrice  \\\n",
       "0            9.5  Jordan     Jordan 4 Retro Military Black          210   \n",
       "1            9.0  Jordan     Jordan 4 Retro Military Black          210   \n",
       "2           10.0  Jordan     Jordan 4 Retro Military Black          210   \n",
       "3            8.0  Jordan     Jordan 4 Retro Military Black          210   \n",
       "4           12.0  Jordan     Jordan 4 Retro Military Black          210   \n",
       "...          ...     ...                               ...          ...   \n",
       "192880      10.0  adidas  adidas Yeezy Boost 350 V2 Sesame          220   \n",
       "192881      12.0  adidas  adidas Yeezy Boost 350 V2 Sesame          220   \n",
       "192882      10.5  adidas  adidas Yeezy Boost 350 V2 Sesame          220   \n",
       "192883      11.0  adidas  adidas Yeezy Boost 350 V2 Sesame          220   \n",
       "192884       9.0  adidas  adidas Yeezy Boost 350 V2 Sesame          220   \n",
       "\n",
       "        salesThisPeriod  days  collaboration  log_hype  log_resalePrice  \n",
       "0                  2476     5              1  9.282103         5.703782  \n",
       "1                  2476     5              1  9.282103         5.703782  \n",
       "2                  2476     5              1  9.282103         5.945421  \n",
       "3                  2476     5              1  9.282103         5.717028  \n",
       "4                  2476     5              1  9.282103         5.966147  \n",
       "...                 ...   ...            ...       ...              ...  \n",
       "192880               13  1211              1  8.588024         5.950643  \n",
       "192881               13  1211              1  8.588024         5.902633  \n",
       "192882               13  1211              1  8.588024         6.040255  \n",
       "192883               13  1211              1  8.588024         5.877736  \n",
       "192884               13  1211              1  8.588024         5.948035  \n",
       "\n",
       "[192885 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab43868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df[\"brand\"], prefix='brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8858088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['brand'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf4d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df[\"sneakerName\"], prefix='SN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e5f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sneakerName'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4273f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoeSize</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>salesThisPeriod</th>\n",
       "      <th>days</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>log_hype</th>\n",
       "      <th>log_resalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.5</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.945421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.717028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.966147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192880</th>\n",
       "      <td>10.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.950643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192881</th>\n",
       "      <td>12.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.902633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882</th>\n",
       "      <td>10.5</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>6.040255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192883</th>\n",
       "      <td>11.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.877736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192884</th>\n",
       "      <td>9.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.948035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192885 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shoeSize  retailPrice  salesThisPeriod  days  collaboration  log_hype  \\\n",
       "0            9.5          210             2476     5              1  9.282103   \n",
       "1            9.0          210             2476     5              1  9.282103   \n",
       "2           10.0          210             2476     5              1  9.282103   \n",
       "3            8.0          210             2476     5              1  9.282103   \n",
       "4           12.0          210             2476     5              1  9.282103   \n",
       "...          ...          ...              ...   ...            ...       ...   \n",
       "192880      10.0          220               13  1211              1  8.588024   \n",
       "192881      12.0          220               13  1211              1  8.588024   \n",
       "192882      10.5          220               13  1211              1  8.588024   \n",
       "192883      11.0          220               13  1211              1  8.588024   \n",
       "192884       9.0          220               13  1211              1  8.588024   \n",
       "\n",
       "        log_resalePrice  \n",
       "0              5.703782  \n",
       "1              5.703782  \n",
       "2              5.945421  \n",
       "3              5.717028  \n",
       "4              5.966147  \n",
       "...                 ...  \n",
       "192880         5.950643  \n",
       "192881         5.902633  \n",
       "192882         6.040255  \n",
       "192883         5.877736  \n",
       "192884         5.948035  \n",
       "\n",
       "[192885 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0296e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6118a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c61c5eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shoeSize</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>salesThisPeriod</th>\n",
       "      <th>days</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>log_hype</th>\n",
       "      <th>log_resalePrice</th>\n",
       "      <th>brand_Alexander McQueen</th>\n",
       "      <th>brand_BAPE</th>\n",
       "      <th>brand_Common Projects</th>\n",
       "      <th>...</th>\n",
       "      <th>SN_adidas Yeezy Slide Glow Green</th>\n",
       "      <th>SN_adidas Yeezy Slide Glow Green (2022) (Restock)</th>\n",
       "      <th>SN_adidas Yeezy Slide Ochre</th>\n",
       "      <th>SN_adidas Yeezy Slide Onyx</th>\n",
       "      <th>SN_adidas Yeezy Slide Pure (First Release)</th>\n",
       "      <th>SN_adidas Yeezy Slide Pure (Restock Pair)</th>\n",
       "      <th>SN_adidas Yeezy Slide Resin</th>\n",
       "      <th>SN_adidas Yeezy Slide Soot</th>\n",
       "      <th>SN_adidas ZX 8000 LEGO</th>\n",
       "      <th>SN_adidas ZX 8000 Sean Wotherspoon Superearth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.5</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.945421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.717028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282103</td>\n",
       "      <td>5.966147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192880</th>\n",
       "      <td>10.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.950643</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192881</th>\n",
       "      <td>12.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.902633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192882</th>\n",
       "      <td>10.5</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>6.040255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192883</th>\n",
       "      <td>11.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.877736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192884</th>\n",
       "      <td>9.0</td>\n",
       "      <td>220</td>\n",
       "      <td>13</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>8.588024</td>\n",
       "      <td>5.948035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192885 rows × 806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        shoeSize  retailPrice  salesThisPeriod  days  collaboration  log_hype  \\\n",
       "0            9.5          210             2476     5              1  9.282103   \n",
       "1            9.0          210             2476     5              1  9.282103   \n",
       "2           10.0          210             2476     5              1  9.282103   \n",
       "3            8.0          210             2476     5              1  9.282103   \n",
       "4           12.0          210             2476     5              1  9.282103   \n",
       "...          ...          ...              ...   ...            ...       ...   \n",
       "192880      10.0          220               13  1211              1  8.588024   \n",
       "192881      12.0          220               13  1211              1  8.588024   \n",
       "192882      10.5          220               13  1211              1  8.588024   \n",
       "192883      11.0          220               13  1211              1  8.588024   \n",
       "192884       9.0          220               13  1211              1  8.588024   \n",
       "\n",
       "        log_resalePrice  brand_Alexander McQueen  brand_BAPE  \\\n",
       "0              5.703782                        0           0   \n",
       "1              5.703782                        0           0   \n",
       "2              5.945421                        0           0   \n",
       "3              5.717028                        0           0   \n",
       "4              5.966147                        0           0   \n",
       "...                 ...                      ...         ...   \n",
       "192880         5.950643                        0           0   \n",
       "192881         5.902633                        0           0   \n",
       "192882         6.040255                        0           0   \n",
       "192883         5.877736                        0           0   \n",
       "192884         5.948035                        0           0   \n",
       "\n",
       "        brand_Common Projects  ...  SN_adidas Yeezy Slide Glow Green  \\\n",
       "0                           0  ...                                 0   \n",
       "1                           0  ...                                 0   \n",
       "2                           0  ...                                 0   \n",
       "3                           0  ...                                 0   \n",
       "4                           0  ...                                 0   \n",
       "...                       ...  ...                               ...   \n",
       "192880                      0  ...                                 0   \n",
       "192881                      0  ...                                 0   \n",
       "192882                      0  ...                                 0   \n",
       "192883                      0  ...                                 0   \n",
       "192884                      0  ...                                 0   \n",
       "\n",
       "        SN_adidas Yeezy Slide Glow Green (2022) (Restock)  \\\n",
       "0                                                       0   \n",
       "1                                                       0   \n",
       "2                                                       0   \n",
       "3                                                       0   \n",
       "4                                                       0   \n",
       "...                                                   ...   \n",
       "192880                                                  0   \n",
       "192881                                                  0   \n",
       "192882                                                  0   \n",
       "192883                                                  0   \n",
       "192884                                                  0   \n",
       "\n",
       "        SN_adidas Yeezy Slide Ochre  SN_adidas Yeezy Slide Onyx  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "192880                            0                           0   \n",
       "192881                            0                           0   \n",
       "192882                            0                           0   \n",
       "192883                            0                           0   \n",
       "192884                            0                           0   \n",
       "\n",
       "        SN_adidas Yeezy Slide Pure (First Release)  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "192880                                           0   \n",
       "192881                                           0   \n",
       "192882                                           0   \n",
       "192883                                           0   \n",
       "192884                                           0   \n",
       "\n",
       "        SN_adidas Yeezy Slide Pure (Restock Pair)  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "192880                                          0   \n",
       "192881                                          0   \n",
       "192882                                          0   \n",
       "192883                                          0   \n",
       "192884                                          0   \n",
       "\n",
       "        SN_adidas Yeezy Slide Resin  SN_adidas Yeezy Slide Soot  \\\n",
       "0                                 0                           0   \n",
       "1                                 0                           0   \n",
       "2                                 0                           0   \n",
       "3                                 0                           0   \n",
       "4                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "192880                            0                           0   \n",
       "192881                            0                           0   \n",
       "192882                            0                           0   \n",
       "192883                            0                           0   \n",
       "192884                            0                           0   \n",
       "\n",
       "        SN_adidas ZX 8000 LEGO  SN_adidas ZX 8000 Sean Wotherspoon Superearth  \n",
       "0                            0                                              0  \n",
       "1                            0                                              0  \n",
       "2                            0                                              0  \n",
       "3                            0                                              0  \n",
       "4                            0                                              0  \n",
       "...                        ...                                            ...  \n",
       "192880                       0                                              0  \n",
       "192881                       0                                              0  \n",
       "192882                       0                                              0  \n",
       "192883                       0                                              0  \n",
       "192884                       0                                              0  \n",
       "\n",
       "[192885 rows x 806 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82376efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['constant', 'shoeSize', 'retailPrice', 'salesThisPeriod', 'days', 'collaboration', 'log_hype', 'brand_Alexander McQueen', 'brand_BAPE', 'brand_Common Projects', 'brand_Converse', 'brand_Crocs', 'brand_Jordan', 'brand_MSCHF', 'brand_New Balance', 'brand_Nike', 'brand_Puma', 'brand_Reebok', 'brand_Salomon', 'brand_Under Armour', 'brand_Vans', 'brand_adidas', 'SN_A Bathing Ape Bape SK8 Sta ABC Camo Blue (2022)', 'SN_Alexander McQueen Oversized Ivory Black', 'SN_Common Projects Original Achilles White', 'SN_Converse Chuck Taylor All-Star Hi Platform White Black (W)', 'SN_Converse Run Star Hike Hi Black White Gum', 'SN_Crocs All-Terrain Clog Carrots', 'SN_Crocs Classic Clog Cinnamon Toast Crunch', 'SN_Crocs Classic Clog Cinnamon Toast Crunch (GS)', 'SN_Crocs Classic Clog Karol G', 'SN_Crocs Classic Clog Lucky Charms Magically Delicious', 'SN_Crocs Classic Clog Staple Sidewalk Luxe', 'SN_Crocs Pollex Clog by Salehe Bembury Crocodile', 'SN_Crocs Pollex Clog by Salehe Bembury Stratus', 'SN_Crocs Pollex Clog by Salehe Bembury Urchin', 'SN_Jordan 1 Elevate Low Onyx (W)', 'SN_Jordan 1 Elevate Low SE University Blue (W)', 'SN_Jordan 1 High Element Gore-Tex Berry', 'SN_Jordan 1 High Element Gore-Tex Light Bone', 'SN_Jordan 1 High Element Gore-Tex Light Curry', 'SN_Jordan 1 High Zoom Air CMFT Anthracite', 'SN_Jordan 1 High Zoom Air CMFT Celestine Blue', 'SN_Jordan 1 High Zoom Air CMFT Easter (W)', 'SN_Jordan 1 High Zoom Air CMFT Patent Chicago (W)', 'SN_Jordan 1 High Zoom Air CMFT Pink Oxford (W)', 'SN_Jordan 1 High Zoom Air CMFT Pumpkin Spice', 'SN_Jordan 1 High Zoom Air CMFT Purple Patent (W)', 'SN_Jordan 1 High Zoom Air CMFT Stadium Green', 'SN_Jordan 1 Low Beaded Swoosh', 'SN_Jordan 1 Low Black Grey Pink', 'SN_Jordan 1 Low Black University Blue White (W)', 'SN_Jordan 1 Low Black White (W)', 'SN_Jordan 1 Low Black White Grey', 'SN_Jordan 1 Low Bred Toe', 'SN_Jordan 1 Low Brushstroke', 'SN_Jordan 1 Low Bulls', 'SN_Jordan 1 Low Cardinal Red', 'SN_Jordan 1 Low Coconut Milk (W)', 'SN_Jordan 1 Low Court Purple White', 'SN_Jordan 1 Low Dark Teal', 'SN_Jordan 1 Low Diamond Shorts', 'SN_Jordan 1 Low Football Grey Aluminum (W)', 'SN_Jordan 1 Low Fragment x Travis Scott', 'SN_Jordan 1 Low Green Toe', 'SN_Jordan 1 Low Gym Red White', 'SN_Jordan 1 Low Hemp White', 'SN_Jordan 1 Low Inside Out Cream White Light Grey', 'SN_Jordan 1 Low Light Madder Root (W)', 'SN_Jordan 1 Low Marina Blue (W)', 'SN_Jordan 1 Low Mocha', 'SN_Jordan 1 Low OG Neutral Grey (2021)', 'SN_Jordan 1 Low Pollen', 'SN_Jordan 1 Low Purple Magenta (W)', 'SN_Jordan 1 Low Reverse Bred', 'SN_Jordan 1 Low SE All-Star (2021)', 'SN_Jordan 1 Low SE Barcelona Cyber Teal', 'SN_Jordan 1 Low SE Light Curry', 'SN_Jordan 1 Low SE Light Smoke Grey Gym Red', 'SN_Jordan 1 Low SE True Blue', 'SN_Jordan 1 Low SE Twine Orange Quartz Corduroy (W)', 'SN_Jordan 1 Low SE Utility White Black Gym Red (W)', 'SN_Jordan 1 Low Shadow Toe', 'SN_Jordan 1 Low Spades', 'SN_Jordan 1 Low Starfish', 'SN_Jordan 1 Low Triple Black', 'SN_Jordan 1 Low Triple White Tumbled Leather', 'SN_Jordan 1 Low UNC (2021)', 'SN_Jordan 1 Low University Blue Black', 'SN_Jordan 1 Low University Gold', 'SN_Jordan 1 Low Wolf Grey (W)', 'SN_Jordan 1 Mid Arctic Orange Black Toe', 'SN_Jordan 1 Mid Armory Navy', 'SN_Jordan 1 Mid Banned (2020)', 'SN_Jordan 1 Mid Barcelona Sweater Red Patent', 'SN_Jordan 1 Mid Barely Rose (W)', 'SN_Jordan 1 Mid Beige White Red', 'SN_Jordan 1 Mid Black Chile Red White', 'SN_Jordan 1 Mid Carbon Fiber All-Star (2021)', 'SN_Jordan 1 Mid Chicago Toe', 'SN_Jordan 1 Mid Coconut Milk (W)', 'SN_Jordan 1 Mid Crater Grey University Blue', 'SN_Jordan 1 Mid Dark Teal Green (W)', 'SN_Jordan 1 Mid Diamond Shorts', 'SN_Jordan 1 Mid Dutch Green (W)', 'SN_Jordan 1 Mid Green Python (W)', 'SN_Jordan 1 Mid Gym Red Black (W)', 'SN_Jordan 1 Mid Gym Red Black White', 'SN_Jordan 1 Mid Hyper Royal Tumbled Leather', 'SN_Jordan 1 Mid Kentucky Blue (W)', 'SN_Jordan 1 Mid Light Smoke Grey (W)', 'SN_Jordan 1 Mid Light Smoke Grey Anthracite', 'SN_Jordan 1 Mid Linen', 'SN_Jordan 1 Mid Metallic Gold Black White', 'SN_Jordan 1 Mid Metallic Orange', 'SN_Jordan 1 Mid Mystic Navy Mint Foam', 'SN_Jordan 1 Mid Oakland', 'SN_Jordan 1 Mid Paris White', 'SN_Jordan 1 Mid Purple Aqua', 'SN_Jordan 1 Mid Reverse Bred (2021)', 'SN_Jordan 1 Mid Reverse Chicago (W)', 'SN_Jordan 1 Mid SE Brown Basalt Oatmeal (W)', 'SN_Jordan 1 Mid SE Brushstroke', 'SN_Jordan 1 Mid SE Coconut Milk Particle Grey', 'SN_Jordan 1 Mid SE Corduroy Sail', 'SN_Jordan 1 Mid SE Craft Inside Out White Grey', 'SN_Jordan 1 Mid SE Dark Chocolate', 'SN_Jordan 1 Mid SE Diamond (PS)', 'SN_Jordan 1 Mid SE Grey Green', 'SN_Jordan 1 Mid SE Light Iron Ore (W)', 'SN_Jordan 1 Mid SE Light Mulberry (W)', 'SN_Jordan 1 Mid SE Particle Grey (W)', 'SN_Jordan 1 Mid SE Pomegranate (W)', 'SN_Jordan 1 Mid SE Purple', 'SN_Jordan 1 Mid SE Siempre Familia', 'SN_Jordan 1 Mid SE Union Royal', 'SN_Jordan 1 Mid SE Voltage Yellow (W)', 'SN_Jordan 1 Mid SE Zen Master', 'SN_Jordan 1 Mid Shadow Red', 'SN_Jordan 1 Mid Signal Blue', 'SN_Jordan 1 Mid Sonics (2021)', 'SN_Jordan 1 Mid Syracuse (W)', 'SN_Jordan 1 Mid Tan Gum', 'SN_Jordan 1 Mid Triple Black', 'SN_Jordan 1 Mid Triple White 2.0 (2020)', 'SN_Jordan 1 Mid Tropical Twist Igloo', 'SN_Jordan 1 Mid UNC (2022) (W)', 'SN_Jordan 1 Mid UNC (W)', 'SN_Jordan 1 Mid USA (2022) (W)', 'SN_Jordan 1 Mid White Black Racer Blue', 'SN_Jordan 1 Mid Wolf Grey Aluminum (W)', 'SN_Jordan 1 Retro High 85 Georgetown', 'SN_Jordan 1 Retro High Black Metallic Gold (2020)', 'SN_Jordan 1 Retro High Black Satin Gym Red', 'SN_Jordan 1 Retro High CO Japan Neutral Grey (2020)', 'SN_Jordan 1 Retro High COJP Midnight Navy (2020)', 'SN_Jordan 1 Retro High Court Purple (W)', 'SN_Jordan 1 Retro High Court Purple White', 'SN_Jordan 1 Retro High Dark Mocha', 'SN_Jordan 1 Retro High Electro Orange', 'SN_Jordan 1 Retro High Element Gore-Tex Black Particle Grey', 'SN_Jordan 1 Retro High Fearless UNC Chicago', 'SN_Jordan 1 Retro High J Balvin', 'SN_Jordan 1 Retro High Light Army Rust Shadow Patina', 'SN_Jordan 1 Retro High Light Smoke Grey', 'SN_Jordan 1 Retro High Lucky Green (W)', 'SN_Jordan 1 Retro High NC to Chi Leather (W)', 'SN_Jordan 1 Retro High OG A Ma ManiÃ©re', 'SN_Jordan 1 Retro High OG Atmosphere (W)', 'SN_Jordan 1 Retro High OG Bordeaux', 'SN_Jordan 1 Retro High OG Brotherhood', 'SN_Jordan 1 Retro High OG Dark Marina Blue', 'SN_Jordan 1 Retro High OG Hand Crafted', 'SN_Jordan 1 Retro High OG Heritage', 'SN_Jordan 1 Retro High OG Hyper Royal', 'SN_Jordan 1 Retro High OG Light Fusion Red', 'SN_Jordan 1 Retro High OG Patent Bred', 'SN_Jordan 1 Retro High OG Prototype ', 'SN_Jordan 1 Retro High OG Rebellionaire', 'SN_Jordan 1 Retro High OG SP Utility Stash', 'SN_Jordan 1 Retro High OG Seafoam (W)', 'SN_Jordan 1 Retro High OG University Blue (PS)', 'SN_Jordan 1 Retro High Obsidian UNC', 'SN_Jordan 1 Retro High Off-White University Blue', 'SN_Jordan 1 Retro High Pollen', 'SN_Jordan 1 Retro High Royal Toe', 'SN_Jordan 1 Retro High Satin Black Toe (W)', 'SN_Jordan 1 Retro High Satin Snake Chicago (W)', 'SN_Jordan 1 Retro High Shadow 2.0', 'SN_Jordan 1 Retro High Shattered Backboard 3.0', 'SN_Jordan 1 Retro High Silver Toe (W)', 'SN_Jordan 1 Retro High Tokyo Bio Hack', 'SN_Jordan 1 Retro High Travis Scott', 'SN_Jordan 1 Retro High University Blue (TD)', 'SN_Jordan 1 Retro High White Black Volt University Gold', 'SN_Jordan 1 Retro High White University Blue Black', 'SN_Jordan 1 Retro Low Golf Chicago', 'SN_Jordan 1 Retro Low Golf Shadow', 'SN_Jordan 1 Retro Low Golf Triple White', 'SN_Jordan 1 Retro Low Golf UNC', 'SN_Jordan 1 Retro Low Golf Wolf Grey', 'SN_Jordan 1 Retro Low OG SP SoleFly', 'SN_Jordan 11 Retro Animal Instinct (W)', 'SN_Jordan 11 Retro Concord (2018)', 'SN_Jordan 11 Retro Cool Grey (2021)', 'SN_Jordan 11 Retro Jubilee 25th Anniversary', 'SN_Jordan 11 Retro Low 72-10', 'SN_Jordan 11 Retro Low Legend Blue', 'SN_Jordan 11 Retro Low Pure Violet (TD)', 'SN_Jordan 11 Retro Low Pure Violet (W)', 'SN_Jordan 11 Retro Playoffs Bred (2019)', 'SN_Jordan 12 Golf Metallic Gold', 'SN_Jordan 12 Retro Black University Gold', 'SN_Jordan 12 Retro Low Easter (2021)', 'SN_Jordan 12 Retro Low Golf Taxi', 'SN_Jordan 12 Retro Playoffs (2022)', 'SN_Jordan 12 Retro Reverse Flu Game', 'SN_Jordan 12 Retro Royalty Taxi', 'SN_Jordan 12 Retro Twist', 'SN_Jordan 12 Retro Utility', 'SN_Jordan 13 Retro Brave Blue', 'SN_Jordan 13 Retro Court Purple', 'SN_Jordan 13 Retro Del Sol', 'SN_Jordan 13 Retro Flint (2020)', 'SN_Jordan 13 Retro Gym Red Flint Grey', 'SN_Jordan 13 Retro Obsidian Powder Blue White', 'SN_Jordan 2 Retro A Ma ManiÃ©re Airness', 'SN_Jordan 2 Retro SP Union Grey Fog', 'SN_Jordan 2 Retro SP Union Rattan', 'SN_Jordan 3 Retro Black Cement (2018)', 'SN_Jordan 3 Retro Cardinal Red', 'SN_Jordan 3 Retro Cool Grey (2021)', 'SN_Jordan 3 Retro Georgetown (2021)', 'SN_Jordan 3 Retro Muslin', 'SN_Jordan 3 Retro Neapolitan Dark Mocha (W)', 'SN_Jordan 3 Retro Patchwork Camo', 'SN_Jordan 3 Retro Pine Green', 'SN_Jordan 3 Retro Racer Blue', 'SN_Jordan 3 Retro SE Fire Red Denim (2020)', 'SN_Jordan 3 Retro SE Unite Fire Red', 'SN_Jordan 3 Retro UNC (2020)', 'SN_Jordan 3 Retro Varsity Royal Cement', 'SN_Jordan 36 Rui Hachimura Black Samurai', 'SN_Jordan 36 Year of the Tiger', 'SN_Jordan 4 Retro Black Cat (2020)', 'SN_Jordan 4 Retro Blank Canvas (W)', 'SN_Jordan 4 Retro Bred (2019)', 'SN_Jordan 4 Retro Fire Red (2020)', 'SN_Jordan 4 Retro Golf Bred', 'SN_Jordan 4 Retro Golf Military Blue', 'SN_Jordan 4 Retro Infrared', 'SN_Jordan 4 Retro Lightning (2021)', 'SN_Jordan 4 Retro Military Black', 'SN_Jordan 4 Retro Off-White Sail (W)', 'SN_Jordan 4 Retro Red Thunder', 'SN_Jordan 4 Retro SP 30th Anniversary Union Desert Moss', 'SN_Jordan 4 Retro Shimmer (W)', 'SN_Jordan 4 Retro Taupe Haze', 'SN_Jordan 4 Retro University Blue', 'SN_Jordan 4 Retro University Blue (PS)', 'SN_Jordan 4 Retro White Oreo (2021)', 'SN_Jordan 5 Low Girls That Hoop (W)', 'SN_Jordan 5 Retro Alternate Bel-Air', 'SN_Jordan 5 Retro Bluebird (W)', 'SN_Jordan 5 Retro Easter (2022)', 'SN_Jordan 5 Retro Fire Red Silver Tongue (2020)', 'SN_Jordan 5 Retro Green Bean (2022)', 'SN_Jordan 5 Retro Jade Horizon', 'SN_Jordan 5 Retro Low CLOT Jade', 'SN_Jordan 5 Retro Low Doernbecher Michael (2022)', 'SN_Jordan 5 Retro Moonlight (2021)', 'SN_Jordan 5 Retro OFF-WHITE Sail', 'SN_Jordan 5 Retro Off-White Black', 'SN_Jordan 5 Retro Racer Blue', 'SN_Jordan 5 Retro Raging Bull Red (2021)', 'SN_Jordan 5 Retro Shattered Backboard', 'SN_Jordan 5 Retro Top 3', 'SN_Jordan 5 Retro What The', 'SN_Jordan 6 Retro Black Infrared (2019)', 'SN_Jordan 6 Retro Bordeaux', 'SN_Jordan 6 Retro Carmine (2021)', 'SN_Jordan 6 Retro Electric Green', 'SN_Jordan 6 Retro Gold Hoops (W)', 'SN_Jordan 6 Retro Midnight Navy (2022)', 'SN_Jordan 6 Retro Mint Foam (W)', 'SN_Jordan 6 Retro Red Oreo', 'SN_Jordan 6 Retro Travis Scott', 'SN_Jordan 6 Retro Travis Scott British Khaki', 'SN_Jordan 6 Retro UNC (2022) (TD)', 'SN_Jordan 6 Retro UNC White', 'SN_Jordan 7 Retro Flint (2021)', 'SN_Jordan 7 Retro SE Sapphire', 'SN_Jordan 8 Retro SE Rui Hachimura Black Samurai', 'SN_Jordan 9 Retro Chile Red', 'SN_Jordan Legacy 312 Low Chicago Red', 'SN_Jordan Lift Off South Beach', 'SN_Jordan MA2 White Sesame', 'SN_Jordan Series .01 SE Dear Rui Black Samurai', 'SN_Jordan Zion 1 Naruto Nine Tails', 'SN_Jordan Zion 1 Naruto Sage of the Six Paths', 'SN_Jordan Zion 1 SP Naruto Kyuubi', 'SN_MSCHF Wavy Baby x Tyga', 'SN_New Balance 2002R Atlas Lemon Haze', 'SN_New Balance 2002R Bone Light Aluminum', 'SN_New Balance 2002R Joe Freshgoods Conversations Amongst Us', 'SN_New Balance 2002R Light Grey', 'SN_New Balance 2002R Marblehead Light Aluminum', 'SN_New Balance 2002R Nightwatch Green', 'SN_New Balance 2002R Protection Pack Mirage Grey', 'SN_New Balance 2002R Protection Pack Phantom', 'SN_New Balance 2002R Protection Pack Rain Cloud', 'SN_New Balance 327 Sea Salt Rust Oxide (W)', 'SN_New Balance 530 Steel Grey', 'SN_New Balance 530 White Nightwatch Green', 'SN_New Balance 530 White Silver Navy', 'SN_New Balance 550 Au Lait (W)', 'SN_New Balance 550 Burgundy Cyan', 'SN_New Balance 550 Cream Black', 'SN_New Balance 550 Joe Freshgoods Conversations Amongst Us', 'SN_New Balance 550 Sea Salt Burgundy', 'SN_New Balance 550 Sea Salt Varsity Gold', 'SN_New Balance 550 Shadow', 'SN_New Balance 550 Syracuse', 'SN_New Balance 550 UNC White University Blue', 'SN_New Balance 550 White Black', 'SN_New Balance 550 White Blue', 'SN_New Balance 550 White Burgundy', 'SN_New Balance 550 White Green', 'SN_New Balance 550 White Green Black', 'SN_New Balance 550 White Grey', 'SN_New Balance 550 White Grey Dark Grey', 'SN_New Balance 550 White Mint Green', 'SN_New Balance 550 White Pink (W)', 'SN_New Balance 550 White Red', 'SN_New Balance 550 White Red Black', 'SN_New Balance 550 White Royal Black', 'SN_New Balance 57/40 Sea Salt Calm Taupe (W)', 'SN_New Balance 574 YURT Salehe Bembury Universal Communication Black Plum', 'SN_New Balance 574 YURT Salehe Bembury Universal Communication Workwear White', 'SN_New Balance 650R Aime Leon Dore White Green', 'SN_New Balance 650R Aime Leon Dore White Grey', 'SN_New Balance 650R Aime Leon Dore White Navy', 'SN_New Balance 650R Aime Leon Dore White Red', 'SN_New Balance 9060 Joe Freshgoods Inside Voices Baby Shower Blue', 'SN_New Balance 9060 Joe Freshgoods Inside Voices Penny Cookie Pink', 'SN_New Balance 990v2 MiUSA Marblehead Incense', 'SN_New Balance 990v3 Bodega Here To Stay', 'SN_New Balance 990v3 Grey (2019/2021)', 'SN_New Balance 990v3 JJJJound Brown Black', 'SN_New Balance 990v3 JJJJound Olive', 'SN_New Balance 990v3 MiUSA Marblehead Incense', 'SN_New Balance 990v5 Grey', 'SN_New Balance 990v5 Grey (GS)', 'SN_New Balance 992 Grey', 'SN_Nike ACG Lowcate Light Iron Ore Green', 'SN_Nike ACG Mountain Fly Low Gore-Tex SE Dark Smoke Grey', \"SN_Nike Air Force 1 High '07 SP Billie Eilish Mushroom\", 'SN_Nike Air Force 1 High White', 'SN_Nike Air Force 1 Indigo (W)', \"SN_Nike Air Force 1 Low '07 Black Black\", \"SN_Nike Air Force 1 Low '07 Essential White Black Paisley (W)\", \"SN_Nike Air Force 1 Low '07 Essential White Green Paisley (W)\", \"SN_Nike Air Force 1 Low '07 Essential White Worn Blue Paisley (W)\", \"SN_Nike Air Force 1 Low '07 LV8 Athletic Club Black University Gold\", \"SN_Nike Air Force 1 Low '07 LV8 Athletic Club Marina Blue\", \"SN_Nike Air Force 1 Low '07 LV8 Go The Extra The Smile\", \"SN_Nike Air Force 1 Low '07 LV8 Next Nature Sun Club\", \"SN_Nike Air Force 1 Low '07 Light Bone White\", \"SN_Nike Air Force 1 Low '07 Medium Blue\", \"SN_Nike Air Force 1 Low '07 Pecan\", \"SN_Nike Air Force 1 Low '07 QS Purple Skeleton Halloween (2021)\", \"SN_Nike Air Force 1 Low '07 QS Uno\", \"SN_Nike Air Force 1 Low '07 White\", \"SN_Nike Air Force 1 Low '07 White Black (2022)\", \"SN_Nike Air Force 1 Low '07 White Black Pebbled Leather\", 'SN_Nike Air Force 1 Low Black (W)', 'SN_Nike Air Force 1 Low Carabiner Swoosh Red', 'SN_Nike Air Force 1 Low Flax (2019/2022)', 'SN_Nike Air Force 1 Low Hare Space Jam', 'SN_Nike Air Force 1 Low LX Off Noir Black', 'SN_Nike Air Force 1 Low LX UV Reactive (W)', 'SN_Nike Air Force 1 Low LX White Pendant (W)', 'SN_Nike Air Force 1 Low Luxe Burnt Sunrise', 'SN_Nike Air Force 1 Low Orange Skeleton Halloween (2020)', 'SN_Nike Air Force 1 Low Our Force 1 Snakeskin', 'SN_Nike Air Force 1 Low SP Supreme Wheat', 'SN_Nike Air Force 1 Low SP Undefeated 5 On It Blue Yellow Croc', 'SN_Nike Air Force 1 Low SP Undefeated 5 On It Dunk vs. AF1', 'SN_Nike Air Force 1 Low Shadow Amethyst Ash (W)', 'SN_Nike Air Force 1 Low Shadow Cashmere (W)', 'SN_Nike Air Force 1 Low Shadow Sail Pink Glaze (W)', 'SN_Nike Air Force 1 Low Supreme Black', 'SN_Nike Air Force 1 Low Supreme White', 'SN_Nike Air Force 1 Low Triple Red', 'SN_Nike Air Force 1 Low UV Reactive Swoosh (W)', 'SN_Nike Air Force 1 Low White (2018) (W)', 'SN_Nike Air Force 1 Low White Gum', 'SN_Nike Air Force 1 Low White Navy Grey', \"SN_Nike Air Force 1 Mid '07 Triple Black (2021)\", 'SN_Nike Air Force 1 Mid QS Independence Day', 'SN_Nike Air Force 1 Mid Stussy Black White', 'SN_Nike Air Force 1 Mid Stussy Hemp', 'SN_Nike Air Force 1 Mid Stussy Light Bone Black', \"SN_Nike Air Force 1 Mid White '07\", 'SN_Nike Air Force 1 Shadow Triple White (W)', 'SN_Nike Air Griffey Max 1 Aqua', 'SN_Nike Air Griffey Max 1 Varsity Royal (2021)', 'SN_Nike Air Huarache Triple Black (2021)', 'SN_Nike Air Max 1 AMD La Ville LumiÃ¨re (W)', 'SN_Nike Air Max 1 CLOT Kiss of Death (2021)', 'SN_Nike Air Max 1 Evolution Of Icons', 'SN_Nike Air Max 1 Patta Waves Monarch (with Bracelet)', 'SN_Nike Air Max 1 Patta Waves Noise Aqua (with Bracelet)', 'SN_Nike Air Max 1 Patta Waves Rush Maroon (with Bracelet)', 'SN_Nike Air Max 1 Premium Blueprint', 'SN_Nike Air Max 1 Premium Wabi-Sabi (W)', 'SN_Nike Air Max 1 SH Treeline', 'SN_Nike Air Max 1 SP Concepts Far Out (Special Box)', 'SN_Nike Air Max 1 SP Concepts Heavy', 'SN_Nike Air Max 1 SP Concepts Mellow', 'SN_Nike Air Max 1 Travis Scott Cactus Jack Baroque Brown', 'SN_Nike Air Max 1 Travis Scott Cactus Jack Saturn Gold', 'SN_Nike Air Max 2 CB 94 Suns', 'SN_Nike Air Max 2017 Cool Grey (2017/2021)', 'SN_Nike Air Max 2017 Triple Black', 'SN_Nike Air Max 270 Black White', 'SN_Nike Air Max 270 Triple Black', 'SN_Nike Air Max 270 White Black', 'SN_Nike Air Max 90 Batman', 'SN_Nike Air Max 90 Duck Camo Orange', 'SN_Nike Air Max 90 Go The Extra Smile', 'SN_Nike Air Max 90 Green Camo', 'SN_Nike Air Max 90 Iron Grey', 'SN_Nike Air Max 90 Metallic Gold (2020) (W)', 'SN_Nike Air Max 90 Metallic Silver (2020) (W)', 'SN_Nike Air Max 90 NRG Bacon (2021)', 'SN_Nike Air Max 90 Premium Lucky Charms (W)', 'SN_Nike Air Max 90 Recraft Triple White', 'SN_Nike Air Max 90 Recraft Wolf Grey', 'SN_Nike Air Max 90 SE Running Club', 'SN_Nike Air Max 90 Smoke Grey Light Photo Blue Metallic Silver Black', 'SN_Nike Air Max 90 Terrascape Black Lime Ice', 'SN_Nike Air Max 90 Terrascape Fuel Orange', 'SN_Nike Air Max 90 Terrascape Sail Sea Glass', 'SN_Nike Air Max 95 Triple Black (2020)', 'SN_Nike Air Max 97 Off Noir', 'SN_Nike Air Max 97 Triple Black', 'SN_Nike Air Max 97 Triple White Wolf Grey', 'SN_Nike Air Max 97 Undefeated Black Militia Green (2020)', 'SN_Nike Air Max BW OG Marina', 'SN_Nike Air Max BW OG Persian Violet (2021)', 'SN_Nike Air Max Correlate Black White Grey', 'SN_Nike Air Max Goadome 865031 Black', 'SN_Nike Air Max Ivo Black White', 'SN_Nike Air Max Koko Triple Black (W)', 'SN_Nike Air Max Plus Triple Black', 'SN_Nike Air Max Plus White', 'SN_Nike Air Max Plus atmos White Hyper Jade', 'SN_Nike Air Max Pre-Day Chlorophyll', 'SN_Nike Air Max Pre-Day Hasta Anthracite', 'SN_Nike Air Max Pre-Day Light Bone', 'SN_Nike Air Max Pre-Day Light Liquid Lime', 'SN_Nike Air More Uptempo Black White (2016/2020)', 'SN_Nike Air More Uptempo Summit White Black Sail (W)', 'SN_Nike Air Presto Hello Kitty (2022)', 'SN_Nike Air Trainer 1 Chlorophyll (2022)', 'SN_Nike Air Trainer 1 Photon Dust Light Smoke Grey', 'SN_Nike Air Trainer 1 SP Dark Smoke Grey', 'SN_Nike Air Trainer 1 SP Travis Scott Grey Haze', 'SN_Nike Air Trainer 1 SP Travis Scott Wheat', 'SN_Nike Air Trainer 1 Utility SP Light Smoke Grey Honeydew Particle Grey', 'SN_Nike Air Trainer SC High Auburn', 'SN_Nike Air VaporMax 2020 Flyknit Newsprint', 'SN_Nike Air VaporMax 2020 Flyknit Oreo', 'SN_Nike Air VaporMax 2020 Flyknit Summit White', 'SN_Nike Air VaporMax 2021 FK Black Anthracite', 'SN_Nike Air VaporMax 2021 FK Particle Grey Liquid Lime', 'SN_Nike Air VaporMax 2021 FK White Black Metallic Silver', 'SN_Nike Air VaporMax Plus Knicks', 'SN_Nike Air VaporMax Plus Triple Black', 'SN_Nike Air VaporMax Plus White', 'SN_Nike Air Zoom Flight 95 OG Black Metallic Silver (2022)', 'SN_Nike Air Zoom Flight 95 SP Supreme Black', 'SN_Nike Air Zoom Flight 95 SP Supreme Hemp', 'SN_Nike Air Zoom Flight 95 SP Supreme University Blue', 'SN_Nike Blazer Low 77 Jumbo White Black Sail', 'SN_Nike Blazer Low 77 Vintage White Black', 'SN_Nike Blazer Low Acronym Black Olive Aura', 'SN_Nike Blazer Low Off-White Black Electro Green', 'SN_Nike Blazer Low Off-White University Red', 'SN_Nike Blazer Low Sacai Black Patent Leather', 'SN_Nike Blazer Low Sacai White Patent Leather', 'SN_Nike Blazer Low sacai KAWS Neptune Blue', 'SN_Nike Blazer Low sacai KAWS Purple Dusk', 'SN_Nike Blazer Low sacai Medium Grey Classic Green', 'SN_Nike Blazer Mid 77 Indigo (W)', 'SN_Nike Blazer Mid 77 Jumbo White Black', 'SN_Nike Blazer Mid 77 Move to Zero Glacier Ice', 'SN_Nike Blazer Mid 77 Vintage Pine Green', 'SN_Nike Blazer Mid 77 Vintage Popcorn', 'SN_Nike Blazer Mid 77 Vintage White Black', 'SN_Nike Blazer Mid 77 White Black (W)', 'SN_Nike Blazer Mid 77 White Indigo', 'SN_Nike Blazer Mid LX White Pendants (W)', 'SN_Nike Classic Cortez White Black (W)', 'SN_Nike Cortez Basic Black White', 'SN_Nike Cortez Basic Forrest Gump (2019)', 'SN_Nike Dunk High 1985 SP Orange Acid Wash', 'SN_Nike Dunk High 1985 SP Yellow Acid Wash', 'SN_Nike Dunk High AMBUSH Deep Royal', 'SN_Nike Dunk High AMBUSH Flash Lime', 'SN_Nike Dunk High Aluminum (W)', 'SN_Nike Dunk High Ambush Active Fuchsia', 'SN_Nike Dunk High Black White (2021)', 'SN_Nike Dunk High Bodega Sail Multi (Friends and Family)', 'SN_Nike Dunk High Cashmere (W)', 'SN_Nike Dunk High Championship Navy', 'SN_Nike Dunk High Championship White Red', 'SN_Nike Dunk High Fragment Beijing (2021)', 'SN_Nike Dunk High Fragment Tokyo', 'SN_Nike Dunk High Game Royal', 'SN_Nike Dunk High Light Chocolate', 'SN_Nike Dunk High Next Nature Summit White (W)', 'SN_Nike Dunk High Panda (2021) (W)', 'SN_Nike Dunk High Pink Prime (W)', 'SN_Nike Dunk High Retro Cargo Khaki (2021)', 'SN_Nike Dunk High Retro Laser Blue', 'SN_Nike Dunk High Retro Re-Raw Halloween (2021)', 'SN_Nike Dunk High Syracuse (2021)', 'SN_Nike Dunk High Syracuse (2021) (W)', 'SN_Nike Dunk Low 3D Swoosh', 'SN_Nike Dunk Low Archeo Pink (W)', 'SN_Nike Dunk Low Black White (2022)', 'SN_Nike Dunk Low Bordeaux (W)', 'SN_Nike Dunk Low Championship Court Purple', 'SN_Nike Dunk Low Championship Goldenrod (2021)', 'SN_Nike Dunk Low Championship Red (2021)', 'SN_Nike Dunk Low Cider', 'SN_Nike Dunk Low Clear Aqua (PS)', 'SN_Nike Dunk Low Coast (W)', 'SN_Nike Dunk Low Coconut Milk', 'SN_Nike Dunk Low Crazy Camo', 'SN_Nike Dunk Low Dark Marina Blue', 'SN_Nike Dunk Low Disrupt 2 Pale Ivory (W)', 'SN_Nike Dunk Low Disrupt 2 Pale Ivory Black (W)', 'SN_Nike Dunk Low Disrupt 2 Phantom University Blue (W)', 'SN_Nike Dunk Low Disrupt 2 White University Blue (W)', 'SN_Nike Dunk Low Disrupt Coconut Milk (W)', 'SN_Nike Dunk Low Doernbecher Zoe', 'SN_Nike Dunk Low EMB NBA 75th Anniversary Brooklyn Nets', 'SN_Nike Dunk Low EMB NBA 75th Anniversary Chicago', 'SN_Nike Dunk Low EMB NBA 75th Anniversary Knicks', 'SN_Nike Dunk Low Easter 2022 (W)', 'SN_Nike Dunk Low Fossil Rose', 'SN_Nike Dunk Low Georgetown', 'SN_Nike Dunk Low Golden Gals Metallic Silver (W)', 'SN_Nike Dunk Low Graffiti Pink', 'SN_Nike Dunk Low Green Glow (W)', 'SN_Nike Dunk Low Grey Fog', 'SN_Nike Dunk Low Harvest Moon (W)', 'SN_Nike Dunk Low Heirloom (W)', 'SN_Nike Dunk Low LX Banana (W)', 'SN_Nike Dunk Low Laser Orange (W)', 'SN_Nike Dunk Low Light Smoke Grey (W)', 'SN_Nike Dunk Low Lime Ice (W)', 'SN_Nike Dunk Low Medium Curry', 'SN_Nike Dunk Low Michigan (2021)', 'SN_Nike Dunk Low Michigan State', 'SN_Nike Dunk Low Midas Gold', 'SN_Nike Dunk Low NH Winter Solstice (W)', 'SN_Nike Dunk Low Next Nature Pale Coral (W)', 'SN_Nike Dunk Low Next Nature Sail (W)', 'SN_Nike Dunk Low Next Nature Sun Club Arctic Orange', 'SN_Nike Dunk Low Next Nature White Black (W)', 'SN_Nike Dunk Low Next Nature White Gym Red (W)', 'SN_Nike Dunk Low Next Nature White Light Orewood Brown (W)', 'SN_Nike Dunk Low Next Nature White Mint (W)', 'SN_Nike Dunk Low Ocean (W)', 'SN_Nike Dunk Low Orange Pearl (W)', 'SN_Nike Dunk Low PRM Halloween (2021)', 'SN_Nike Dunk Low Premium Vast Grey', 'SN_Nike Dunk Low Purple Pulse (W)', 'SN_Nike Dunk Low Retro Black Hyper Cobalt (2021)', 'SN_Nike Dunk Low Retro Next Nature Sequoia', 'SN_Nike Dunk Low Retro Sun Club Wheat Grass Orange', 'SN_Nike Dunk Low Retro White Black Panda (2021)', 'SN_Nike Dunk Low Rose Whisper (W)', 'SN_Nike Dunk Low SE Barber Shop Black', 'SN_Nike Dunk Low SE Barber Shop Grey', 'SN_Nike Dunk Low SE Easter Candy (W)', 'SN_Nike Dunk Low SE Next Nature Rift Blue', 'SN_Nike Dunk Low SE Sail Multi-Camo', 'SN_Nike Dunk Low SP Undefeated 5 On It Black', 'SN_Nike Dunk Low SP Undefeated Canteen Dunk vs. AF1 Pack', 'SN_Nike Dunk Low Safari Mix (W)', 'SN_Nike Dunk Low Sail Light Bone (W)', 'SN_Nike Dunk Low Scrap Black Gum', 'SN_Nike Dunk Low Scrap Latte', 'SN_Nike Dunk Low Scrap Sea Glass', 'SN_Nike Dunk Low Siempre Familia', 'SN_Nike Dunk Low Sunset Pulse (W)', 'SN_Nike Dunk Low Team Red (2022)', 'SN_Nike Dunk Low Triple White (2021) (W)', 'SN_Nike Dunk Low Two Tone Grey', 'SN_Nike Dunk Low UNC (2021)', 'SN_Nike Dunk Low Undefeated 5 On It Dunk vs. AF1', 'SN_Nike Dunk Low Union Passport Pack Argon', 'SN_Nike Dunk Low Union Passport Pack Court Purple', 'SN_Nike Dunk Low Valerian Blue', 'SN_Nike Dunk Low Venice (W)', 'SN_Nike Dunk Low Vintage Green (W)', 'SN_Nike Dunk Low Vintage Navy (W)', 'SN_Nike Dunk Low White Black (2021) (W)', 'SN_Nike Dunk Low White Green Noise (W)', 'SN_Nike Dunk Low White Gypsy Rose (PS)', 'SN_Nike Dunk Low White Paisley (W)', 'SN_Nike Dunk Mid Social Status Free Lunch Strawberry Milk', 'SN_Nike Dunk SB Low Stingwater Magic Mushroom', 'SN_Nike Dunk Scrap Grey Haze Phantom', 'SN_Nike Epic React Flyknit 2 Black White', 'SN_Nike Epic React Flyknit 2 Hydrogen Blue Sapphire Hyper Pink', 'SN_Nike Free Run 2 Black White (2021)', 'SN_Nike Go FlyEase Black', 'SN_Nike Go FlyEase Black Gum', 'SN_Nike Go FlyEase Celestine Blue', 'SN_Nike Go FlyEase White Sail', 'SN_Nike Hot Step Air Terra Drake NOCTA Black', 'SN_Nike Hot Step Air Terra Drake NOCTA White', 'SN_Nike KD 14 Aunt Pearl', 'SN_Nike KD 14 Seasonal Black Laser Crimson', 'SN_Nike KD 15 Aimbot', 'SN_Nike Killshot 2 J Crew Sail Midnight Navy', 'SN_Nike Killshot 2 Leather Sail Gum', 'SN_Nike Kobe 5 Protro Undefeated Hall of Fame', 'SN_Nike Kobe 6 Protro Grinch (2020)', 'SN_Nike Kobe 6 Protro Mambacita Sweet 16', 'SN_Nike Kwondo 1 G-Dragon Peaceminusone Triple White', 'SN_Nike Kyrie 4 Low Bright Crimson Aquatone', 'SN_Nike Kyrie 4 Low Keep Sue Fresh Dynasty', 'SN_Nike Kyrie 7 1 World 1 People Yellow', 'SN_Nike Kyrie Flytrap 4 Bright Mango', 'SN_Nike LD Waffle sacai CLOT Kiss of Death 2 Cool Grey', 'SN_Nike LD Waffle sacai CLOT Kiss of Death Net Orange Blaze', 'SN_Nike LD Waffle sacai Undercover Black Bright Citron', 'SN_Nike LD Waffle sacai Undercover Night Maroon Team Royal', 'SN_Nike LeBron 18 Low Wile E. vs Roadrunner Space Jam', 'SN_Nike LeBron 19 Doernbecher Sam David', 'SN_Nike LeBron 8 South Beach (2021)', 'SN_Nike LeBron 9 Big Bang (2022)', 'SN_Nike LeBron 9 Low LeBronald Palmer (2022)', 'SN_Nike LeBron 9 Watch the Throne (2022)', 'SN_Nike M2K Tekno Summit White (W)', 'SN_Nike M2K Tekno White Pure Platinum', 'SN_Nike P-6000 Triple White', 'SN_Nike PG 5 Mismatched Multi-Color', 'SN_Nike PG 5 Playstation White', 'SN_Nike PG 6 All Star Weekend (2022)', 'SN_Nike PG 6 Black Mint', 'SN_Nike PG 6 Fluoro', 'SN_Nike RYZ 365 White (W)', 'SN_Nike React Element 55 Black White', 'SN_Nike React Phantom Run Flyknit 2 Platinum Tint Dark Teal (W)', 'SN_Nike React Phantom Run Flyknit 2 Volt', 'SN_Nike React Phantom Run Flyknit 2 White Black', 'SN_Nike React Vision Black White', 'SN_Nike SB Dunk High Hawaii', 'SN_Nike SB Dunk High New York Mets', 'SN_Nike SB Dunk High Oski Great White', 'SN_Nike SB Dunk High Pass~Port Work Boots', 'SN_Nike SB Dunk High Pro KCDC', 'SN_Nike SB Dunk High Pro Mineral Slate Suede', 'SN_Nike SB Dunk High Supreme By Any Means Black', 'SN_Nike SB Dunk High Supreme By Any Means Navy', 'SN_Nike SB Dunk Low Barcelona', 'SN_Nike SB Dunk Low Blue Raspberry', 'SN_Nike SB Dunk Low Chlorophyll', 'SN_Nike SB Dunk Low Fog', 'SN_Nike SB Dunk Low Gnarhunters', 'SN_Nike SB Dunk Low Mummy', 'SN_Nike SB Dunk Low Polaroid', 'SN_Nike SB Dunk Low Pro Bart Simpson', 'SN_Nike SB Dunk Low Pro Dark Russet', 'SN_Nike SB Dunk Low Pro ISO Orange Label Unbleached Pack Lilac', 'SN_Nike SB Dunk Low Pro Paisley Brown', 'SN_Nike SB Dunk Low Pro Parra Abstract Art (2021)', \"SN_Nike SB Dunk Low Pro St. Patrick's Day (2022)\", 'SN_Nike TC 7900 Sail (W)', 'SN_Nike Vaporwaffle sacai Black Gum', 'SN_Nike Vaporwaffle sacai Dark Iris', 'SN_Nike Vaporwaffle sacai Sail Gum', 'SN_Nike Vaporwaffle sacai Villain Red Neptune Green', 'SN_Nike Waffle One Summit White', 'SN_Nike Zoom Pulse Black Teal Tint', 'SN_Nike ZoomX Vaporfly Next% 2 White Metallic Silver', 'SN_Puma MB.01 LaMelo Ball Galaxy', 'SN_Puma MB.01 LaMelo Ball Queen City', 'SN_Puma MB.01 LaMelo Ball Red Blast', 'SN_Puma MB.01 LaMelo Ball Rick and Morty', 'SN_Reebok Club C 85 Tyrrell Winston', 'SN_Reebok Question Low Blueprint', 'SN_Salomon XT-4 Hidden NY White', 'SN_Under Armour Curry Flow 9 Sesame Street Cookie Monster', 'SN_Vans Vault UA Knu-Skool VR3 LX Imran Potato Black White', 'SN_adidas Campus 80s South Park Towelie', 'SN_adidas Forum Low Bad Bunny Back to School', 'SN_adidas Forum Low Home Alone', \"SN_adidas Forum Low M&M's Yellow\", 'SN_adidas NMD Hu Pharrell Human Race Triple Black Pack', 'SN_adidas NMD R1 Primeblue Triple Black', 'SN_adidas Response CL Bad Bunny', 'SN_adidas Samba Black White Gum', 'SN_adidas Samba OG Cloud White Core Black', 'SN_adidas Samba Star Wars Boba Fett Sarlacc Pit', 'SN_adidas Samba Vegan White Gum', 'SN_adidas Superstar AEC Sean Wotherspoon Superearth Black', 'SN_adidas Superstar Bape ABC Camo Green', 'SN_adidas Trae Young 1 Tie-Dye', 'SN_adidas Ultra Boost 4.0 DNA Grey Three', 'SN_adidas Ultra Boost 4.0 DNA Triple Black', 'SN_adidas Ultra Boost 4.0 DNA White', 'SN_adidas Ultra Boost 5.0 DNA Oreo', 'SN_adidas Ultra Boost DNA 4.0 Core Black', 'SN_adidas Yeezy 450 Cinder', 'SN_adidas Yeezy 450 Cloud White', 'SN_adidas Yeezy 450 Dark Slate', 'SN_adidas Yeezy 450 Resin', 'SN_adidas Yeezy 450 Sulfur', 'SN_adidas Yeezy 500 Blush', 'SN_adidas Yeezy 500 Clay Brown', 'SN_adidas Yeezy 500 Granite', 'SN_adidas Yeezy 500 Taupe Light', 'SN_adidas Yeezy 500 Utility Black', 'SN_adidas Yeezy 700 V3 Arzareth', 'SN_adidas Yeezy 700 V3 Clay Brown', 'SN_adidas Yeezy 700 V3 Copper Fade', 'SN_adidas Yeezy 700 V3 Dark Glow', 'SN_adidas Yeezy 700 V3 Fade Carbon', 'SN_adidas Yeezy 700 V3 Kyanite', 'SN_adidas Yeezy 700 V3 Mono Safflower', 'SN_adidas Yeezy 700 V3 Safflower', 'SN_adidas Yeezy Boost 350 V2 Ash Blue', 'SN_adidas Yeezy Boost 350 V2 Ash Pearl', 'SN_adidas Yeezy Boost 350 V2 Ash Stone', 'SN_adidas Yeezy Boost 350 V2 Beluga Reflective', 'SN_adidas Yeezy Boost 350 V2 Black (Non-Reflective)', 'SN_adidas Yeezy Boost 350 V2 Black Red (2017/2020)', 'SN_adidas Yeezy Boost 350 V2 Blue Tint', 'SN_adidas Yeezy Boost 350 V2 Bone', 'SN_adidas Yeezy Boost 350 V2 Carbon', 'SN_adidas Yeezy Boost 350 V2 Cinder', 'SN_adidas Yeezy Boost 350 V2 Citrin (Non-Reflective)', 'SN_adidas Yeezy Boost 350 V2 Cloud White (Non-Reflective)', 'SN_adidas Yeezy Boost 350 V2 Core Black White', 'SN_adidas Yeezy Boost 350 V2 Cream/Triple White', 'SN_adidas Yeezy Boost 350 V2 Dazzling Blue', 'SN_adidas Yeezy Boost 350 V2 Desert Sage', 'SN_adidas Yeezy Boost 350 V2 Earth', 'SN_adidas Yeezy Boost 350 V2 Israfil', 'SN_adidas Yeezy Boost 350 V2 Light', 'SN_adidas Yeezy Boost 350 V2 MX Oat', 'SN_adidas Yeezy Boost 350 V2 MX Rock', 'SN_adidas Yeezy Boost 350 V2 Mono Cinder', 'SN_adidas Yeezy Boost 350 V2 Mono Clay', 'SN_adidas Yeezy Boost 350 V2 Mono Ice', 'SN_adidas Yeezy Boost 350 V2 Mono Mist', 'SN_adidas Yeezy Boost 350 V2 Natural', 'SN_adidas Yeezy Boost 350 V2 Sand Taupe', 'SN_adidas Yeezy Boost 350 V2 Sesame', 'SN_adidas Yeezy Boost 350 V2 Static Black (Reflective)', 'SN_adidas Yeezy Boost 350 V2 Synth (Reflective)', 'SN_adidas Yeezy Boost 350 V2 Tail Light', 'SN_adidas Yeezy Boost 350 V2 Yeezreel (Non-Reflective)', 'SN_adidas Yeezy Boost 350 V2 Yeshaya (Non-Reflective)', 'SN_adidas Yeezy Boost 350 V2 Zebra', 'SN_adidas Yeezy Boost 350 V2 Zyon', 'SN_adidas Yeezy Boost 380 Alien Blue', 'SN_adidas Yeezy Boost 380 Calcite Glow', 'SN_adidas Yeezy Boost 700 Bright Blue', 'SN_adidas Yeezy Boost 700 Enflame Amber', 'SN_adidas Yeezy Boost 700 Faded Azure', 'SN_adidas Yeezy Boost 700 MNVN Bright Cyan', 'SN_adidas Yeezy Boost 700 MNVN Geode', 'SN_adidas Yeezy Boost 700 V2 Cream', 'SN_adidas Yeezy Boost 700 V2 Static (2018/2022)', 'SN_adidas Yeezy Boost 700 Wash Orange', 'SN_adidas Yeezy Boost 700 Wave Runner Solid Grey', 'SN_adidas Yeezy Foam RNNR MX Sand Grey', 'SN_adidas Yeezy Foam RNNR MXT Moon Gray', 'SN_adidas Yeezy Foam RNNR Mineral Blue', 'SN_adidas Yeezy Foam RNNR Mist', 'SN_adidas Yeezy Foam RNNR Ochre', 'SN_adidas Yeezy Foam RNNR Sand', 'SN_adidas Yeezy Foam RNNR Stone Sage', 'SN_adidas Yeezy Foam RNNR Sulfur', 'SN_adidas Yeezy Foam RNNR Vermillion', 'SN_adidas Yeezy Slide Enflame Orange', 'SN_adidas Yeezy Slide Glow Green', 'SN_adidas Yeezy Slide Glow Green (2022) (Restock)', 'SN_adidas Yeezy Slide Ochre', 'SN_adidas Yeezy Slide Onyx', 'SN_adidas Yeezy Slide Pure (First Release)', 'SN_adidas Yeezy Slide Pure (Restock Pair)', 'SN_adidas Yeezy Slide Resin', 'SN_adidas Yeezy Slide Soot', 'SN_adidas ZX 8000 LEGO', 'SN_adidas ZX 8000 Sean Wotherspoon Superearth']\n"
     ]
    }
   ],
   "source": [
    "dfnames = df.copy()\n",
    "dfnames = dfnames.drop(['log_resalePrice'], axis = 1)\n",
    "\n",
    "columns = dfnames.columns.tolist()\n",
    "columns.insert(0, 'constant')\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ce940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('log_resalePrice',axis =1).values\n",
    "y = df['log_resalePrice'].values\n",
    "\n",
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ca1e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49173\\AppData\\Local\\Temp\\ipykernel_14316\\2855883272.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
      "C:\\Users\\49173\\AppData\\Local\\Temp\\ipykernel_14316\\2855883272.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_test = s_scaler.transform(X_test.astype(np.float))\n"
     ]
    }
   ],
   "source": [
    "s_scaler = StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
    "X_test = s_scaler.transform(X_test.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a4c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Neural Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f824ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# having 9 neurons is based on the number of available features\n",
    "model = Sequential()\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(18,activation='relu'))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='Adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5487051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1055/1055 [==============================] - 5s 3ms/step - loss: 0.8075 - val_loss: 0.0281\n",
      "Epoch 2/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 3/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0291 - val_loss: 0.0296\n",
      "Epoch 4/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0290 - val_loss: 0.0280\n",
      "Epoch 5/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0285 - val_loss: 0.0281\n",
      "Epoch 6/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0275 - val_loss: 0.0270\n",
      "Epoch 7/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0266 - val_loss: 0.0265\n",
      "Epoch 8/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0261 - val_loss: 0.0255\n",
      "Epoch 9/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0252 - val_loss: 0.0258\n",
      "Epoch 10/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0248 - val_loss: 0.0234\n",
      "Epoch 11/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 12/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0237 - val_loss: 0.0235\n",
      "Epoch 13/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0229 - val_loss: 0.0227\n",
      "Epoch 14/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 15/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0216 - val_loss: 0.0218\n",
      "Epoch 16/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0210 - val_loss: 0.0203\n",
      "Epoch 17/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 18/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 19/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 20/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 21/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 22/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0190 - val_loss: 0.0198\n",
      "Epoch 23/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 24/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0186 - val_loss: 0.0184\n",
      "Epoch 25/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0186 - val_loss: 0.0185\n",
      "Epoch 26/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 27/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0182 - val_loss: 0.0183\n",
      "Epoch 28/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 29/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0179 - val_loss: 0.0176\n",
      "Epoch 30/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0179 - val_loss: 0.0182\n",
      "Epoch 31/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0177 - val_loss: 0.0185\n",
      "Epoch 32/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 33/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 34/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0175 - val_loss: 0.0183\n",
      "Epoch 35/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 36/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 37/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0174 - val_loss: 0.0173\n",
      "Epoch 38/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0172 - val_loss: 0.0175\n",
      "Epoch 39/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0172 - val_loss: 0.0179\n",
      "Epoch 40/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0171 - val_loss: 0.0179\n",
      "Epoch 41/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 42/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 43/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0170 - val_loss: 0.0174\n",
      "Epoch 44/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0170 - val_loss: 0.0171\n",
      "Epoch 45/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 46/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 47/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 48/400\n",
      "1055/1055 [==============================] - 3s 2ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 49/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0169 - val_loss: 0.0167\n",
      "Epoch 50/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0167 - val_loss: 0.0176\n",
      "Epoch 51/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0168 - val_loss: 0.0169\n",
      "Epoch 52/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0168 - val_loss: 0.0176\n",
      "Epoch 53/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 54/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0166 - val_loss: 0.0173\n",
      "Epoch 55/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 56/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 57/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0166 - val_loss: 0.0169\n",
      "Epoch 58/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 59/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0165 - val_loss: 0.0170\n",
      "Epoch 60/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 61/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 62/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0164 - val_loss: 0.0164\n",
      "Epoch 63/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0169\n",
      "Epoch 64/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 65/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0164 - val_loss: 0.0171\n",
      "Epoch 66/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 67/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 68/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0174\n",
      "Epoch 69/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 70/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 71/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 72/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 73/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0163 - val_loss: 0.0164\n",
      "Epoch 74/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0163\n",
      "Epoch 75/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0165\n",
      "Epoch 76/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 77/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0179\n",
      "Epoch 78/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 79/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0167\n",
      "Epoch 80/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0162 - val_loss: 0.0162\n",
      "Epoch 81/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0165\n",
      "Epoch 82/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 83/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 84/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0161 - val_loss: 0.0161\n",
      "Epoch 85/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0161 - val_loss: 0.0163\n",
      "Epoch 86/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 87/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0163\n",
      "Epoch 88/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 89/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0160 - val_loss: 0.0162\n",
      "Epoch 90/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 91/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0172\n",
      "Epoch 92/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 93/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 94/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 95/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 96/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0159 - val_loss: 0.0161\n",
      "Epoch 97/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 98/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0177\n",
      "Epoch 99/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 100/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 101/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 102/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 103/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 104/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 105/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0172\n",
      "Epoch 106/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 107/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0166\n",
      "Epoch 108/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 109/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 110/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0158\n",
      "Epoch 111/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 112/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0168\n",
      "Epoch 113/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 114/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0165\n",
      "Epoch 115/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 116/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0169\n",
      "Epoch 117/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 118/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 119/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0157 - val_loss: 0.0161\n",
      "Epoch 120/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 121/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0159\n",
      "Epoch 122/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 123/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0163\n",
      "Epoch 124/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0156 - val_loss: 0.0161\n",
      "Epoch 125/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 126/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 127/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 128/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0164\n",
      "Epoch 129/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 130/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 131/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0165- ETA: 0s - loss:\n",
      "Epoch 132/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0165\n",
      "Epoch 133/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 134/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0166\n",
      "Epoch 135/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 136/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0160\n",
      "Epoch 137/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0176\n",
      "Epoch 138/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0163\n",
      "Epoch 139/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 140/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 141/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 142/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0161\n",
      "Epoch 143/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 144/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 145/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0155 - val_loss: 0.0158\n",
      "Epoch 146/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 147/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0159\n",
      "Epoch 148/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 149/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0162\n",
      "Epoch 150/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 151/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 152/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 153/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0165\n",
      "Epoch 154/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 155/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 156/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 157/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0163\n",
      "Epoch 158/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0160\n",
      "Epoch 159/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 160/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 161/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0164\n",
      "Epoch 162/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 163/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0154 - val_loss: 0.0156\n",
      "Epoch 164/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 165/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.01560s - loss: 0\n",
      "Epoch 166/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 167/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0166\n",
      "Epoch 168/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0163\n",
      "Epoch 169/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 170/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 171/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 172/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 173/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 174/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 175/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 176/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 177/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 178/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 179/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 180/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0159\n",
      "Epoch 181/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 182/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 183/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 184/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 185/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 186/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 187/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 188/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 189/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0161\n",
      "Epoch 190/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0161\n",
      "Epoch 191/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 192/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0159\n",
      "Epoch 193/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0161\n",
      "Epoch 194/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0162\n",
      "Epoch 195/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 196/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 197/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 198/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 199/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 200/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 201/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0155\n",
      "Epoch 202/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 203/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 204/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 205/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0164\n",
      "Epoch 206/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 207/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 208/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 209/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 210/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 211/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0152 - val_loss: 0.0163\n",
      "Epoch 212/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 213/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 214/400\n",
      "1055/1055 [==============================] - 4s 3ms/step - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 215/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 216/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 217/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0165\n",
      "Epoch 218/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 219/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 220/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0160\n",
      "Epoch 221/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0157A: 0s -\n",
      "Epoch 222/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 223/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 224/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 225/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 226/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 227/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0161\n",
      "Epoch 228/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 229/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 230/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 231/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 232/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 233/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0170\n",
      "Epoch 234/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 235/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0162\n",
      "Epoch 236/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0164\n",
      "Epoch 237/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0161\n",
      "Epoch 238/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 239/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0161\n",
      "Epoch 240/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0175\n",
      "Epoch 241/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 242/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 243/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 244/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 245/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 246/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0162\n",
      "Epoch 247/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 248/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 249/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 250/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 251/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 252/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 253/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0158\n",
      "Epoch 254/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 255/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 256/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 257/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 258/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 259/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 260/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 261/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 262/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 263/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0165\n",
      "Epoch 264/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 265/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 266/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 267/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 268/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 269/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0155\n",
      "Epoch 270/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 271/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0156\n",
      "Epoch 272/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 273/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 274/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0162\n",
      "Epoch 275/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 276/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0159\n",
      "Epoch 277/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 278/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 279/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 280/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 281/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 282/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0168\n",
      "Epoch 283/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 284/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 285/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 286/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 287/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0150 - val_loss: 0.0157\n",
      "Epoch 288/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 289/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 290/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 291/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 292/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 293/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 294/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 295/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 296/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 297/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 298/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 299/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0153: 1s - loss\n",
      "Epoch 300/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 301/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 302/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 303/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 304/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 305/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 306/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 307/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 308/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 309/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 310/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 311/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 312/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 313/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 314/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0160\n",
      "Epoch 315/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 316/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 317/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0159\n",
      "Epoch 318/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 319/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 320/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0159A: 0s\n",
      "Epoch 321/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0154\n",
      "Epoch 322/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 323/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 324/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 325/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 326/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 327/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 328/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 329/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 330/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 331/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 332/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 333/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 334/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 335/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 336/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 337/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 338/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 339/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 340/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 341/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 342/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0159\n",
      "Epoch 343/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 344/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 345/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0160\n",
      "Epoch 346/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 347/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 348/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 349/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 350/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 351/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0158\n",
      "Epoch 352/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 353/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 354/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 355/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0165\n",
      "Epoch 356/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 357/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 358/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156 0s - loss: 0.\n",
      "Epoch 359/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 360/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 361/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 362/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 363/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 364/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 365/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0165\n",
      "Epoch 366/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 367/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 368/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 369/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 370/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 371/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 372/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 373/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 374/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 375/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 376/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 377/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 378/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0157TA: 0s - loss: \n",
      "Epoch 379/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 380/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 381/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 382/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 383/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 384/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0155\n",
      "Epoch 385/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 386/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0161\n",
      "Epoch 387/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 388/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 389/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0156\n",
      "Epoch 390/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 391/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 392/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 393/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 394/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 395/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0153E -\n",
      "Epoch 396/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 397/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0158\n",
      "Epoch 398/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 399/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 400/400\n",
      "1055/1055 [==============================] - 3s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 9)                 7254      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 7,957\n",
      "Trainable params: 7,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=128,epochs=400)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19402c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.08902877414982426\n",
      "MSE: 0.015329435051143574\n",
      "RMSE: 0.12381209573843573\n",
      "VarScore: 0.9326514573744591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c9cdc36b50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAEvCAYAAABRxVXuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABBmklEQVR4nO3deXRT1doG8GcnDZBWoEVApTKJCIoIaBWU7yKDiMpgLyiD4Cyo1wnQKnhR8IIXFFEuKiooTiCWsTIooIATCtrSIoKggkwFpVoK0gZIk/39EZLmpCfzSU6G57eWS7ubpq+kmqd7eLeQUoKIiIiIlAx6F0BEREQUixiSiIiIiFQwJBERERGpYEgiIiIiUsGQRERERKSCIYmIiIhIRUoknrR+/fqyWbNmkXhqIiIiIk0VFBT8KaVs4DkekZDUrFkz5OfnR+KpiYiIiDQlhNirNs7lNiIiIiIVDElEREREKhiSiIiIiFQwJBERERGpYEgiIiIiUsGQRERERKSCIYmIiIhIBUMSERERkQqGJCIiIiIVDElEREQUe9asAXS+vSMi15IQERERhSQ3Fxg8uOpjKXUrhTNJREREpL85cwAhlAFp61b96gFDEhEREelpxgxHOLr77qqxn392zCBdfLF+dYEhiYiIiPTw7LOOcPTII46PU1OBvXsd4ahlS31rO40hiYiIiKJDSmDMGEc4GjfOMXbWWcChQ0B5OdCkib71eeDGbSIiIoosux146CFg5syqsfPPBzZtAurV068uPxiSiIiIKDJsNuCOO4C5c6vGLr0UWL8eqFNHt7ICxZBERERE2rJagYEDgby8qrEuXYBPPnHsPYoTAe1JEkKMEkJsE0L8KISYL4SoFenCiIiIKM5YLECPHkCNGlUBqU8f4MQJ4Isv4iogAQGEJCFEJoCHAWRJKS8GYAQw2PdXERERUdI4fhy4/HJHCFq3zjF2yy2OGaXly4GaNfWtL0SBnm5LAWAWQqQASAVwMHIlERERUVw4cgS48EKgdu2qK0RGjHDsRZo3D0iJ7109fkOSlLIYwAsA9gE4BOColHKN5+OEECOEEPlCiPySkhLtKyUiIqLYcPgwkJnpOJm2Y4dj7LHHHKfY3ngDMCRGh6FAltsyANwIoDmARgDShBDDPB8npZwlpcySUmY1aNBA+0qJiIhIXwcOOE6lnXUWcPD0otKECY5wNHWqo/9RAgkk6l0D4DcpZYmU0gpgCYCrIlsWERERxYzdux0BqHFj4O+/HWPTpjmaQ44fn3DhyCmQkLQPQCchRKoQQgDoAeCnyJZFREREutu+3RGAWrSoGnvjDUc4Gj1av7qixO+OKinlJiHEIgCbAVQCKAQwK9KFERERkU4KCx1NH93NnQsMHapPPToJaNu5lHI8gPERroWIiIj09M03QOfOyrGlS4HsbF3K0Vt8n80jIiKioOQVFmPq6p04WGZBo3Qzcnq1QvZfPwE9eyofuGZN9bEkw5BERESUJPIKizF2yVZYrDYAQOv8z5E9tofiMV++tQRjD9fFwbUWNCpY5whRHTKjXme1IBflGgBASCk1f9KsrCyZ72wqRURERDGh85R1KC6zoO/2L/Dy8qmKz914x3RsOev8al9jEICEY6+2UQgM6dgYk7LbRqxGzyAHAGaTEZP7t41YUBJCFEgpszzHOZNERESUIHq++Dl+OVzu+rhlwzR8Orqr6+POX3yE51fNUH7NXa/ilwZNvT6n3W0uxSYl5m7ch7kb9yHdbMKEfm00Dy5TV+9UBCQAsFhtmLp6Z9RnkxiSiIiI4oznclS31g0wf9M+2DwWh345XI5mY1biru8/wtPrZuN5t89dPWIW9mY0CrmGMosVI3OLkL+3VNOZpYNllqDGI4khiYiIKI54LkcVl1kwd+M+1cc+tGE+Hv16nuvj4zXM6Hn3TByqo93NGPM27kNW03rI7pCpyV6iRulmFKsEokbpZq1KDhhDEhERURxRW45SkBJjvngH921a7Bo6nJaBG+6cgT/TMjSvRwJ4Zvk2AKgW3sYu2QoAQQWlnF6tVPck5fRqpV3RAWJIIiIiiiNqsywAIKQdE9e8hmFFn7jGdtXLRP9hL+CouXZEazpSYcUzy7dpspfI+dhYON3GkERERBRHjELA5nYy3Wi3YdrKF5G9/QvX2A9nn48hg/+L8pqpUavrSIVVdTyUvUTZHTJ1CUWeGJKIiIjiiDMgmWxWzMybgp6/bnJ97tsmbXHHTRNw0lRTr/Kq0WMvkVYYkoiIiCIgr7AYzyzf5pphMZsMqGUyoqzCikbpZqTWMCiO66vp3KIebs5qolh6yoAVM+c/jSv3bXU97tPzO+Jf2WNgNZoi8u+SajKgwmr3+Zh0swknK+0xsZdIKwxJREREGssrLEbOoi2wup3Jt1jtsJwOGt72FXnasKsUG3aVAgDSTlbgtf+NxCW//1r1fS66Go/2Hg2bwahh9dVJCAzr1ASLC4q9bhrv0+4cZDWtFxN7ibTCkERERBQmz6PvFacqFQEpHHVOHMfS9x9Fi9Ji19jc9tfjqWvvhxQGTb6HPxarDet3lGBy/7Z4dMEWxZ4op/U7SjApO3JdsfXAkERERBQGtb5FWqhffgQfv/0wGpYfcY29fkV/TOl6JyCEJt8jGAfLLMjukIlRuUVeP59oGJKIiIhClFdY7HVmJVRnH/sTn711P844VRU6pv3fULzceYhm3yMUzg3YsdTsMdIYkoiIiELgnEHSKiA1OXIIX84arhib2P0evHV5dlDP49kiwMl5SWz+3lKvHbp9cW7AjqVmj5HGkEREROSDt6s21JonhqJlyV58OucBxdiYXg/iw/bXhfR80wa2w9TVO1FcZnEFpky3up17huZv2h9wwEs3m1xfF0vNHiNNSA2nCJ2ysrJkfn6+5s9LRETxLZS7vdS+Jn9vqetNXgCokWLAyUrlEXWjEOh0Xgb2/GVRXAS7YsshlFnUGx9GU5vff8XKd0cqxh7um4NlF12t+fca1qkJJmW3Vb0Yd+UPh1xtClJNBlhtEla7MhtkpJowvm+baq+VFne1xQIhRIGUMqvaOEMSERFFg+cGZ6BqCcjbG6va1xgA+O7YE9suO7Adi+c9rhi7p/9T+Kxlx4h+X39H+AHH6zHgskzVIOn5WoXyesYqbyEpOmcHiYgo6aldzOq82yuYr4nXgNR5TxH2PNdHEZCGDpqEZk+siHhAAhzLa/6WB51H/dNqVt+N4/lahfJ6xhvuSSIioqjwdkTc19HxRDhW3vOXjZi9ZJJibMDQ51Fw7kVRrSPQ/UeBvh6hvJ7xhiGJiIiiIpSj496+Jh702/45Zix/QTHW+/bp2Hb2+brUIwQQSE5yvh7+XqtkaAXA5TYiIoqKnF6tYDYpr8/wd3Rc7Wti/Y1rcNEq7HmujyIgXXP3TDR7YoVmAckUwh+COcVQ7c+y2mNOvx6BvFahvJ7xhjNJREQUFaEcHff2Ne6n22LF3d/n4al1byrGuoyYjX0Z52jy/OlmEyb0qzphNnT2t6573ZyMAvB2G4rFasdLg9pXO922fkeJ4mPn5+uaTahlMrgu5PV8rZKhFQBPtxERUVxrMfbjiIQlAaCu2eS7XYCUePibDzH663muob9rmHHt3TNxqE4DTerITDdjw5juAT++85R1qstg/p4nkU6rBYun24iIKCEN6dg4Is8r4djHo7pEJSXGrp+DPc/3dQWk38+oh8senIu2oxZqFpCA4DdCh7oMlgyn1YLF5TYiIoprk7LbAqjeQToj1YQTVhssVkfTAIMA7NIxo+K+zJSeanI1U/RUVmFVLFEZYMfEVTNxy5ZVrsfsqncu/nnrCzhW64yI/PsFuxE61GWwZDitFiyGJCIiinuTstu6wpIvzg7R8zbuQ6N0M14a1B7ZHTK9LlE1Sjc7rvJoexZw++3ABx+4Prfl7Ja4ZfCzKK+Z6hpLNRlgsdqRnmqClMBRixV1zSYIAdfenvKTlapLeI5QZ9fkTjT360cClQyn1YLFkEREREnBc89NcZkFY5dsBeD90tbHuzcH+vYFVqxwjW9oegnuGjAeJ001XWPB7BvytvdnfN82APTbCJ1MF9cGiiGJiIiSgq89N86A4wwozVMFFix7BvUnbax68I034qMnX8KY5TtxMowg4W85TK9N0slwWi1YPN1GRERJofmYlVB7xxMAfpvS2/HB338DXbsCmzdXPWDYMOCddwCjYzN0olzqSlW8nW7jTBIRESUFn3tuSkuBjh2BX3+t+sT99wOvvAIYlAfBQ9nvQ/GJLQCIiCgpqB2NP/fkMax9YTBw5plVAenxxwG7HZg5s1pAouTCmSQiIkoK7ntu5L59WPvm/TBbT1Q9YOJEYNw4naqjWMSQRERESSO7tgXZY3soB196CRg5Upd6KLYxJBERUeL78UegrUcfpdmzgXvu0aceigsMSURElLgKCoAsj0NL8+cDgwfrUw/FFYYkIiJKPF99BXTpohxbtszRGJIoQAxJRESUONasAXr1Uo599hnQo4f644l8YEgiIqK45N7UcVBxAabMHa/4/L33zUCDXl2x/vsSHPx0JRs/UtAYkoiIKCaNy9uK+Zv2wyYljEJgSMfGrktsnfefXVv0Gf63Ypri63rfPh3bzj7f8cHGfa5x97vaGJQoEH5DkhCiFYBct6HzADwtpZweqaKIiCi5jcvbirluAccmpevjSdltsXPiNPy09CXF1/S4+zXsqt/Y5/NarDaMWlCEUblFnFkiv/yGJCnlTgDtAUAIYQRQDGBpZMsiIqJE5+sOtPmb9qt+TeqM/wH/fAtPnP7YDoGuI2ZhX8Y5AX9f55WlnFkif4JdbusBYJeUcm8kiiEiouTgXC6zWG0AqgcWm/vl61LikQ3zMWrDB66h4zXTcM1dr+L3OvXDqsNitWHq6p0MSaQq2JA0GMD8SBRCRETJY+rqna6A5OQeWIxCwGa349/r38Lw7/NcjzlU+0yc8+t2fFZsxdElWwGP5wiF2qW3REAQIUkIUQNAPwBjvXx+BIARANCkSRNNiiMiosSTV1jsNZgcLLMAdjs+LJiDyz9d7Br/5czGGDBsKo7VOgNpr2xGxSkbpOozBM8ohEbPRIkmmJmk6wFsllL+ofZJKeUsALMAICsrS6ufXSIiSiDOZTY1RrsNM1a+CDzXB5efHis65wLcMvhZVNQwux5Xfir82SN3iqU9IjfBhKQh4FIbEREFwXNzdvnJymrLbDUqrXh96bPovju/arBHD3S7+lH8Vm6PeI1GIdB8DPsoUXUBhSQhRCqAngDujWw5RESUKNQ2Z7urZT2BdxeMR8cD21xjq1t2wiPZYzBlSBZ+yy3SrBYBeF2ec84k8bQbeQooJEkpKwCcGeFaiIgogahtzgaAM05WIPeDMWhzeLdrbPHF3ZFz/SOwG4wAgJEaBSQBoFG6Gd1aN8DigmLVetzxtBu5Y8dtIiIKi/uSWnqqCSesNlis1ZfJ0i3H8NF7o9G07HfX2HsdemN8z3shhUHzuoxCYNfkG1wfZzWtp1j687l5nAgMSUREFAbPJbUjFdZqj2lw/Ag+eftB1K846hqb2ekmPN/ldiCCJ8uGdFR2387ukKmYIeo8ZZ1qUGqUbq42RsmJIYmIiELmbUkNABodO4x1s+9DrcpTVY//x6149apBmtZgAGBKMeBkpWP2SgAY2qmJ6543b3J6tVIEPAAwm4zI6dVK0/oofjEkERFRyNSWppqVFuPz2cpzPhN6jMA7Wf00+Z5pNYyuNgDpZhMm9GsT0h4i59d4uxqFiCGJiIhU+bpbzfl5dxeU7MGaOQ8qxnKufxgLL7lWs5qGBTBDFAzPJTgidwxJRERJxDP4OE59HXBttDYI4JaOTZDVtJ7Xu9UA4Jnl21z7jy459DOWvTda8X0e6PcEVl74D83qzkg1YXxf/zNG/oIdUTCEjECn0aysLJmfn+//gUREpBlnQCguszjuPpMSmW5BIa+wGDmLtsBq0+b/+1fs/xELPhijGLtrwNNYd/4Vmjw/AEwf1D7gkOO5iRxw7DGa3L8tgxL5JIQokFJmeY5zJomIKAF4BgS1Bon/XrpVk4DUZXcB3ls4XjE2ZPCz+LZpu7Cf211mujmocOPv0lyiYDEkERElAF+nzCxWGyYs2xb2nWe9dn6DN/L+qxjrP2wqNmdeGNbzqhEAurVuACDwJTRv/Y3Y94hCxZBERJQA/AWBMkv1/kWByt62HtNXTFOM3XDHDGw/67yQn9MfCWBxgWNjuHunbF9Xh3hrEMm+RxQqhiQioiDE6sZgXx2kQzW08GM8u2amYqzH3a9hV/3GXr5CWxarDfM37XctHbqPqy2hse8RaY0hiYgoQGoXtupxIapaUFMLCKEasWkxnvz8bdfHNmHA1SNm4UD62WE/d7A8A5KT2swZ+x6R1ni6jYgoQN6uschMN2PDmO5RqWFc3lbM27hPcaO9s8N0VtN6mLBsW2hLa1Ji1Ncf4JFv5ruGjtZMw7V3v4o/atcPu+5QCQBq71LR/DOnxMfTbUREYdJ7Y3BeYXG1gAQ4QsS8jfsAwHU1R8CkxFPr3sTd+R+5hoprN0DfO6ajNLVueAVrILWGEXYJLqGRLhiSiIgCpMXG4FD2NLn3P/JGApi3aR8CXRwQ0o7Jq17B4B/WuMZ+PrMJbhr2PI7VOiOwJ4mCilM2vDSoPZfQSBcMSUREAQp3Y7DanqZRuUXI31vq9aoNtQaJ3gQSkIx2G/63/AX02fGVa2xzo1YYNmgSKmrE3imwRm69kpxBaerqnQCiuw+MkhNDEhFRgMLdGKzWy8i5VJbVtJ7q8/jqfxSMGpVWzFoyCV1/K3CNfdW0Pe656WmcTKkR9vOryTw9w6Y2A+bsCO6LM4DGyoZ5Sj7cuE1EFCXNx6xU3YQMOEKDXcpqwcvX1wTCfOoE3lvwNC4v3u4a++SCq/BQv8dRaYzs78kCwEuD2qvOvg24LFPR/wgATEaBtBopOGqxKv4cor1hPlbbPFDkcOM2EZHOfPUycr9GJGfhFgCOWZJQ+x/VPlmOBfOewIUle1xjiy7ugcevfxh2gzH44kOgtlTmHjqymtaLuU7anLUidwxJRERRktOrFUblFvmdGbLaJSYs24bsDpnI6dUKo3OLEOiZtXTLMSx/dxQaH/3DNfbOpX3wzDUjIIUh5Nr9MRoEbPaqfzP3vVrZHTJVA4a3cU/R7KTN+9/IHUMSEZGHSC23ZHfIRP7eUtVj/J7KLFZ0+M8a1D+jRkABqcHxUqya8yDOtBxzjb1y5UC88I9bASGCrnX6oPYB15puNqFPu3OwfkdJRJaootlJW+82DxRbGJKIiNxovdyiFrgAqF634elIhRVHKnw3hsw8ehjrZo9ATVula+z5Lrdh5pUDg67V3cjcIq+NHDNSTTh+ohLW0zNHZRYrFhcUY3L/thGZbYlmJ23e/0buuHGbiMiNlpuE8wqLg1oqC0bz0mKsn32vYmz8Nffi3cv6RuC7VREA0lNNquEtEbpgq7VcMJuMEQuAFBu4cZuIyAv32R5vvzaGstwydskPmgekViV7sHrOg4qxx24YiUVtr9H4O6mTgNfZrURYkuL9b+SOIYmIklqgzRpD6aptsWoXkdod3ImP3n9UMfZAvyew8sJ/aPY9wpUoS1KBbiinxMeQRERJLZBmjcF21c5ZtAVWmzZbGa7Y/yMWfDBGMXbnTeOxvsXlmjx/KNLNJpystPM+NUp4DElElNT8LRFlqiy3eNuM7e9+tWBcvbsA7y4crxgbMvhZfNu0nSbPHyqzyYgJ/doA4JIUJT5u3CaipOZtozbgmDFJq5mC4jILhAjsbrRwXbdzA17Pm6wY++ewF1CY2Try39yDAHBVi3rY85eFYYgSGjduExGpyOnVCiNzi1Q/V2axoszi2KQc6YDU/8e1eHHlS4qx6++cgZ8anhfZb+zDS4PaMxBRUmNIIiLNRPLOq0CeO5Tvn90hE88s3+a3H1GkDNu8EpM+fU0x1uOe17DrzMa61OOU6XalCFGyYkgiIk1E8s6rQJ47nO/f+5JzAuosraV7Ny3C2M/fcX1sNRjRbfgbOJB+dhSrUMdN2EQO3JNERJqI5E3tgTy3v71FE/q1UZ15iuoskpQY/dVcPPxtrmvoSK3a6HXXKzhc+8zo1OCHUQhMG9iOs0iUVLgniYgiKpJ3XgXy3L5OlZVZrBi9oAgTlm1DmcUKoxB+rwTRlJQYv3YW7ixY7ho6UKcB+t0+HaWpdaNXRwCiGZAiuTxLpAWGJCLSRCTvvNLiue0Srk3Y0QpIBrsNU1a9jIFbP3ON7ajfFAOHPodjtc6ISg3Bmrp6J4Dwl0j9ieTyLJFWDHoXQESJIadXK5hNRsWYVntb/D13XmFx2N9DSym2SryaNxm7p97oCkgFjVrjwlGLcN3dr8ZsQAKqworan2leYTE6T1mH5mNWovOUdWH9uas18bRYba6QRhQLOJNERJqI5J1Xns9dy2TAyUobRuYWYfSCIvWr6nVQs/IUZi+eiC57Cl1jXzbrgOEDnsLJlBo6VhYcZ1jxbKCp5cxPJJdnibTCkEREmonknVfO5x6XtxVzN+5zjdtjICCZT53A3NxxuOzgDtfYylad8UjfHFQa4/N/s55hxdfMTyiveSSXZ4m0Ep//9RJR0pq/ab/eJbjUPlmOhXMfR+s/97rGFl58DZ64/iHYDUYfXxn7PMOK1jM/Ob1aVbtYmK0HKNYwJBFRWKJ9Qimqp9K8yKg4iuXvjsK5xw67xt6+rC+e6TECEELHyrShFla0nvmJ5PIskVYYkogoZFrvUxk6+1ts2FXq+rhzi3qYN/xKxWOifnzfTYPjpVjz1gPIOPG3a+zlKwdh2j+GxW04Sjeb0KfdOVi/o8RnWInEzE8kl2eJtMCQREQh03KfimdAAoANu0oxdPa3mDf8SteMlR4B6dyjf2DdrHtRw17pGnvu6tvxWqebo16LljJSTSh8+tqAHsuZH0pGAYUkIUQ6gDcBXAzHOZK7pJTfRrAuIooD3ho4+mrs6MkZfrx9zYZdpdVmrKLlvL8OYN2b9ynGnup5H96/tE9U64gEk1FgfN82QX0NZ34o2QQ6k/Q/AKuklDcJIWoASI1gTUSksUjtG/K29GUMcOkp0PAzMrcolPJCduHh3fjk7YcVY4/dMBKL2l4T1TqClZFqQu9LHEtnxWUW1+uTmW5Gt9YN/C6pEZGS35AkhKgDoAuAOwBASnkKwKnIlkVEWgl131Agwcrb0pdNympH9QEgrYYRFadsaHT6TXv+pv0xsRHbqf3Bnch7/1HF2P03jsEnrf9Pp4r8EwB+m9Jb7zKIElIgM0nnASgB8LYQoh2AAgCPSCnLI1oZEWkilH1DgQarTC8nngBUC0gAUH6q6vnUPq+XTvt+wIfzn1SM3XHTeHze4nKdKgoc+woRRU4g15KkALgUwGtSyg4AygGM8XyQEGKEECJfCJFfUlKicZlEFKpQ+tsEemVEt9YNwi9QR113fY89z/VRBKTBQ/6LZk+siIuAJAD2FSKKoEBmkg4AOCCl3HT640VQCUlSylkAZgFAVlZW7MyfEyW5UPrbBBqs1u+Iz1+Irt/xNV77aIpiLPvWaShqFF+BQ4KXwRJFkt+QJKX8XQixXwjRSkq5E0APANsjXxoRaSGU/jaBBqt4u2drwNa1mPbxS4qx6++cgZ8anqdTReHJ1HipLdqNQYliXaCn2x4CMO/0ybbdAO6MXElEpKVA+9u4v0GaTdVX4k1GgZxerVT7GcW6WzevwMRPX1eMdb/ndew+81ydKgqOySAAAVhtVZP0Ao69XZ2nrNMkzGjdGJQoEQgZgZMlWVlZMj8/X/PnJaLICOQovgFAi4Zp+OVw/JzZuH/jQjzxxbuuj08aU9Bj+Bs4UPcsHasKjgAwtFMTZDWt5+onJeBYanMym4yY3L9tWGGm85R1qrOHmelmbBjTPeTnJYoHQogCKWWW5zg7bhMlEW/LKWobtT3ZgfgISFLisa/ex4PfLnANlZrr4Lo7X8bh2mfqWFhoJBx7vyZlO0KQWpgJtcu5O60vsCVKBAxJREnC13JKQrwRSokJn72BOzavcA3tr3sW+t32Io6k1tWxsPC5vz6RCjNaX2BLlAgYkoiShK9j/d7eIOOBwW7D85/MwE0/rnWN/dSgGQYOfQ5/10zTsTLt1DWbXP8cqTATiQtsieIdQxJRkvA1A/HSoPa63I0WjhRbJV5e9jyu//kb11h+5oW4deBEWGrU0rEy7bnf8hKpMMMLbImqY0giShK+ZiCyO2Qif29pTHXB9qZm5SnMXjwRXfYUusY+b34ZRvQfh1MpJh9fGb/KKqyuf45kmOEFtkRKPN1GpKNo9KVxfg+1U1Emo0BajRQctTjehGO5C6z51AnMy/03Lj1Y1fV7Rav/w8i+j6HSGH+/7wkAtUwGWKx2v481CgG7lJzdIYoQnm4jzbDhnDYiefGst+/hHoLSahhRfsqGMotV9WtjRZ0Tx7Fw3uNo9WfVLFdu254Ye92DsBuMOlYWuszTr9uo3KKAHu+8BJi9i4iiiyGJgsKGc9qJ5MWzvr6Hk/Oy2VhVr+Iolr8zEpl/V119MueyfvhPj+HKTTpxxLPnkHOGLxhaHPcnosAwJFFQQnljJ3VaXjw7Ydk21dmleDza3/Dvv/DpW/9C3ZNVPZlmXDkIL/5jWNyGIyfP10NtE3Yoz0NEkcGQREFhwzntBHuUO6+w2OusQ5nF6lo2c84u5e8thRBABLYdRsS5Zb/j81kjkCKr9uhM7noH3uh4k45Vacv52uYVFuOZ5dtw5PSGbM+9Yv6kp5pcz8Olb6LIYUiioLDhnHaCOcrtXGYLlMVqi4uTagDQ4q/9WPvm/YqxcT3vx9xLe+tUUWQ4X9u8wmLkLNqiuIdNwnHtizAI2Oz+45KUXPomigaGJAoKG86Fz/23/7pmE2qZDCirsPqcCQjk2pB4c9Efu/HxOw8rxkb3HoUlF/fQqaLIGnBZputaEfeA5GQHIAIISABw1GLl0jdRFDAkUVDYcC48nr/9l1msMJuMeGlQe59/hr6WMzNSTa5lm3jQoXgHls59TDF2X/ZYrGrVWaeKomP+pv3IalrP52sZ6JJbo3Qzl76JooAhiYLGhnOhC/W3f2/LnM6j5PHQLfvKvT9g/odPKsZuv/kZfHHeZTpVFByzyYATVnvIvaRsUmLskq1I9xFqjUK4jvt7r8Mxc+vtZByXvom0w5BEFIRwN8oG+9u/eyNIT843S8/ZvVjbp91t1/d4e9EzirFBQyZjU5O2OlUUGovVjmGdmoS118titeGE1Qajyt4jk0Fg0BWNsbiguFrgdW7Az/T4mePSN1FkMSQRBUiLjbLBbHz3/H6eDAIYlVuEqat3IqdXK2wY0x15hcUYGWCDwki7YcfXmPnRFMXYjbdOw5ZG8fsm/sHGfejcoh427CoN+Tmcm7RrnW7mCQDpZhMm9GuD7A6ZyGpaL6AgzqVvosjjtSREAeo8ZZ3XJS/3BoG+jMvbqjoTkWoyoP9l52L9jhIUl1lgEECAe3hjTps/dmHlO48oxq6782XsaNhcp4q05ZzNcT/CbzYZUMtkxJEKa0BLZs7nCfTnhogii9eSEIVJi42y63eUqI5XWO2K8BSPAan9wZ148JsPcc2u711j3Ya/gd/qJdbMxsEyi+q+vHF5WzF/037YpIRRCHQ6LwOb9x31OhPIDdZEsY8hiShAWvSISsQ3xsv3/4iHvslFlz2FOFKrNl74xzC8d2kfHKt1ht6lRYTa6+05Q2iTEht2laJzi3rYuPuI6swSN1gTxT6GJKIAadEjylvQijtSovPeLXj4mw/Rcf+PKElNx+Sud2Bu+xtQXjNV7+oixgCovt7zN+1XffzG3UcwbWA7brAmilMMSUQBCnajrNpJuJxerTB6QVFcLqcBAKRE1935ePibD3HpwZ34/Yx6eKbHcMxv1wsnTLX0ri7iXvTSz8rbHiSblJpusOY1JETRxY3bRBrwfPNKrWHAL4fLqz2uhlHglEq35VgnpB3X/rIRD36Ti7Z/7MKBOg3xWqebsLBtT5xKMeldXsQ571bzPILv1GLsx6pBySgEdk2+QZMa1E47mk1GTO7flkGJKEzcuE0UIn+/vau1BvAm3gKSwW5D7x1f44FvF6D1n3uxJ/0c5Fz/MJa26Y5KY+L+76NlwzRUnLKjuMyiuHzWW9uHIR0bq55aHNKxsWY18RoSouhL3P/LEYXBvYmj55vkqNwiLMzfhz1/WXCwzAJDgEe+44nRbsON2z/HA98uRIvSA/jlzMZ4pM+jWHFhF9gMRr3LixjnTBHgCCVA9atC1ILJpGxHY0z3021DOjZ2jWuB15AQRR9DEpEHz5khzzdJCSiaCSZSQDLZrBiwdS3+tXEhmhz9A9sbNsf9N47BqlZXQQqD3uVFlLNvkb8mnoB6MJmU3VbTUORJi9OVRBQchiQiD2rLGomuZuUpDPxhDe7buBiZf5dgy9kt8Z8eI/DZ+Vc47sRIAs7gE8jrbxACzcesjOrmaS1OVxJRcBiSiDwk0/KF+dQJ3FL0Ce79bgkalh/B95kXYex1D+LL5pcmTThycs7IBPL6O2cPnXuU8veWYv2OkoieOuM1JETRx5BE5CFhehn5cMbJCty2eQXu/j4PZ1qO4Zsml+CRvjn4tknbpAtHTs4ZmWBff4vVhnkb9/nd3K0FtU7fkca2A5TMGJKIPOT0aoWchVtgjdtmRt7VOXEcd+Yvw50Fy5B+4jg+b34ZXr5qEArOvUjv0nSVbja53vjVlrX8CWRzdzzS4lJnonjGkESkxmMyxWgQqF0zBUct1rg8zdbiz/14Y+mzOOv4X6h9yoI1LTvh5SsHYes5LfUuTXcCwIR+bVwfO9/83S+wDUUiLNuy7QAlO4YkSmihLBVMXb0TVo9+Rja7xN8nKgEAdcwpYb15RtNFf+zGx+887Pr466btMKn7PdjRsLmOVUXf9EHtkb+3VLEsBjgC0tBOTVR/JlJrBPY6u7eIcJcIp87YdoCSHUMSJQzPQNStdQMsLigOeqnA2xuAc/YoHgLSpcU/YcncHMXYvf98EqsvuEqnivRjOD0ruLigWDUgeR7bD6QFgHsHbs+fMyBxTp2x7QAlO4YkimmBzgSp7Z3wnDUAqpYKAO+nhOJ54/aVe7dg/of/VozddvMz+PK8y3SqKDJaNkzDgSMnAto3dEvHJqrLRhLA+h0l1R4fSAsAZ0DaMKY7ACCrab2E3NzMtgOU7BiSKGYFs2nU25ugmuIyi2JjtvvzAkD5yUqN/g2ip/uv32HO4v8oxgbeMgXfNb5Yp4oiw72TtVqAzt9bqtr1uvmYlarPpzZrGOhSkvvj9Dh1Fg1sO0DJjiGJYlYwm0aD3SPheXLNYrXhmeXbcPxEZVydauvz05d4ZdnzirG+t72UkBuyBaC4LFYtmGR3yFTteh3MslGgM4nJsuSUqAGQKBAMSRRxofZZCWbTqBZLZPGw18jp5h/WYOonMxRjve56BTsbNNOnoCgIJ5QEs2wUSAsALjkRJQeGJIqoQJfM1IJUML/9d2vdQPUW9kRzR/4yTFg7SzHWdfgb2FMvsX/TVwslwYTvYJaNnGMTlm1DmaV6cE43mzChXxvOrhAlAYYkiqhAlszG5W1V7Vg84LLMgE8NqW3ATSQPfJOLnK/ed31sSamJHsNfw8E6DXWsKjqMQmBy/7bVQnWwTQ6DWTbK7pCJqat3qoaktJopDEhESYIhiSLK35JZXmGx11No63eUYHL/tl5/+3efSYifXURBkBJPfPEu7t+0yDVUkpqOG+58GSVnZOhYmPYMAlDbCmY2GasFJMB3+HZ+PtyNxuwRREQMSRRR/pbMpq7e6TXg+HozCqSXTbwS0o7/fPo6bi382DX2W8Y5yL71RRw119axMu0JAQzt2MR1hL64zALj6Y7mmT4CjrefDeeMkhbXaLBHEBExJFHE5BUWo+JU9eP0Ao43r85T1vncbF3XbPL6hhdIL5t4Y7Db8MLH09F/23rX2I9ntcDgIZNxvGaqjpVFhskoMPWmdgCqZn58BSN33gKMUQjNrtFgjyAiCigkCSH2APgbgA1ApZQyK5JFUfzzNdPjvvfI25UOAo5ZBm9veIm05GGyWfHqR8/h2l82usY2Nb4Yt988ASdMtXSsLLKsNolRuUVIMQrXNTCBzvx4CzDegnMoPy/sEUREwcwkdZNS/hmxSiihBDrTI1H97ivndRHzvJxWO1hmQXqqKa6O7KupaT2JOYufQee9P7jG1ra4HPdnP4lTKSYdK4seCVS7Jy+QmR9vAca5ZOcp1CUy9ggiSm5cbiNVofY2cgrmN3fPoJRaw4ispvWw8odDqkEoPdWE4yfiNyClnrJg/vwn0e73X1xjyy7sglF9HoXNYNSxstgRyM+PtwDDJTIi0kqgIUkCWCOEkADekFLO8vcFFL9COV7tKdjmju5zCeWnbMhZtAWQ6lu643UGqc6J41j6/mNoUXrANfZBu174d68HIIVBx8piTzgzPwCXyIhIG4GGpM5SyoNCiIYAPhVC7JBSfun+ACHECAAjAKBJkyYal0nRFMx1IGryCovDvv/Mcwkmnp1ZXoaV7zyMs4+XusZmX56NZ7vd7dh4RQrhzvxwiYyItBJQSJJSHjz998NCiKUArgDwpcdjZgGYBQBZWVmJ8w6XhMLpD5PIR/ODdfaxP/HpW/ej9qmqP7eXOt+C/3UekpThyHm0X404vd7KmR8iiiV+Q5IQIg2AQUr59+l/vhbAf/x8GcWxcPrDJOLR/GA1LvsdX71xj2JsUre78OYV/XWqSH8CwJCOjb1fHSOB36b0jmpNRET+BDKTdBaApcLxm28KgA+klKsiWhXpKpz+MIl0ND9Y5/+5D5+99S/F2JO9HsAH7a/XqaLYIQFMym6LFVsOqV71wQaNRBSL/IYkKeVuAO2iUAvFiHA2vwa7YdsogHjfftTm91+x8t2RirFH+jyKj9p006egGJR5OgRN6NeGp8+IKG6wBUAMCPe4fSR4bn4dOvtbjMwtcn3csmEaKk7Zq9XcrXUD70sqKuI5IF164CcsmZejGBvxz39jzQVX6lRRbHIPQTx9RkTxREgvGynDkZWVJfPz8zV/3kSkttHZ26WeoTx3qG9G7l+bYgCs9rBKSSid9xRhXu44xditA/+Dr5pfqlNFscVkEDijVgrKKqwMQUQUF4QQBWq3iXAmSWfhHrf3JpxeR55fy4Dk0OPXTXhr8UTF2E1Dn0P+uW10qig2mIwCaTVScNTCUEREiYUhSWfhHLf3JZzwxRNqSn23f4GXl09Vjt32Erae01KniqLP2RE9M92Mbq0bYP2OEi6XEVHCY0jSWTjH7X0JJ3wl8wk1d4O2rMZzq15WjF171yv4uUEzfQqKErVLh50ByXk/GgMSESUDhiSdhXPc3pdwwlewJ9QSzV3ff4Sn181WjF09Yhb2ZjTSqaLo8dXw0blkG851NURE8YQXRuksu0MmJvdvi8x0MwQcv61rsWk7p1crmE3Ky1IDDV9qX5sMHtowH3ue6+MKSOWmWrjq/jlo9sSKpAhIALwGJMARoLwt4RIRJSKebktg4/K2Yv6m/bBJCaMQ6HReBvb8ZcHBMgsMHv2JWjZMw6eju7o+zissxjPLt1W7TNZkcMw02OP46L6ClBjz+du477slrqHDaRm44c4Z+DMtQ8fCYovZZPS6T02A3bKJKL7xdFsCCOZIf15hMeZ/t981M2CTEht2VV2w6tmf6JfD5ej54ueuoJTdIRNTV++sFpKsCZKOhLRj4prXMKzoE9fY7oxG+Oet03DUXFvHymKP+16kSOyfIyKKVQxJPsRSk8dgj/T/e+lW2IIMNL8cLld8nIgbuI12G6atfBHZ279wjW09qwUGD5mM8pqpOlamL7XN2oAjIG0Y0931MbtlE1EyYUjyIpw+Q5Hg60i/8/PuYa78VPhH+BNpA7fJZsXMvMno+et3rrGNjS/GHTdPwAlTLR0r05/JKDDo8sZYXFDsMwCxWzYRJRvuSfKi85R1qgHB8zdrT5GafWo+ZqXqb/qAY5+Q+zKYr/0j/uxx21ui1g083tS0nsQ7iybgyn1bXWOftbgc9//zSViNJh0rizyDAOxSfZbIve+R82c0lmZOiYiiiXuSghRKn6FIzj75mtXx3CcUTqhpPmZltTdI9zvb4kXayQrM//BJXPL7r66xvIuuxqO9R8NmSIyTe3um9PYa5gHHaTSjAbB6bEBLN5swoV+baj+Tnvf1ERElO4YkL0LpM6T1FSPuv9mnp5qqzRiFIq2G0edSnIQj3I3KLUL+3lJMym6L/L2lQV1aq6c6J45j6fuPokVpsWtsXvvrMO7af0GKxOl4YRQCgHqfLSdvPytpNVMYhoiIAsCQ5EUoTR61vGLEc1bqSIUVJqMI+nmcjEJgSMfGmJTdFs3HroS/VVYJYO7GfXETjuqXH8HHbz+MhuVHXGNvXNEfk7veCYjQ/9xilfPUYiizfYm4IZ+IKBIYkrwIZZOqlleMqM1KWW3SZ0dkNWo9bCKwDU035xwrwWdv3o806wnX2LT/G4qXOw/RsarwZaSaUFZh9boPLdPtZ8rZriHQTfY8sk9EFBiGJB+C3aOR06sVchZtUewBMRlFSEekvf22b5Oy2sZsk1Gg0iZV31AT9Q2xyZFD+HLWcMXYxO734K3Ls/UpSGOe/ak8ef5Mqc18mgwCEMo9STyyT0QUOIYkrandDBoCb7NS3i4ZBQLrYZNXWIx41rJkLz6d84BibGyvBzG//XU6VRR96WaT6qZroPrMp9pYrO1H4qk6IopVDEkamrp6Z7XNsla7DGnjtq89Ub5muHy92Tj3OcWjNr//ipXvjlSMPdz3MSy7qKsu9ejFbDJiQr82qp/z9nMRy4Ej1vqRERG5Y58kDXnrZRTq3VbO37CLyyyuvUjOv2f6+I3b22/mvo6Lx6rLDmzH4nmPK8aG9x+HT1t20qmi6MpINSG1RkrCzrKE2o+MiEhL7JMUBVpu3AaqfpN2/03buWnb22/cvn4zj6dTTf/3WyHmLnhKMTZs4ER83byDThVpz9ns0RuzyYjxfav3M0okWp4IJSLSWuI0jokBOb1awWxSNioMd6Os2ik3J/drSXw93mK14dEFW5CeGvsdpnv+shF7nuujCEgDhj6PZk+sSKiANH1Qe+ye3BvTB7VHurnqdTGc7laQmW7G5P5tEzogAd5/gUjUAwdEFF+SZiYplM2hwX6N5+bZumYThABG5RZh6uqdIS2V+PuN2vPzvk7F+Tsxpad+2z/HjOUvKMb63D4dP559vk4VRdbU1TsxKrcIjdLNqt2vfVFbhvW1/BrLQulHRkQULUkRkkLZHBrqhlLn5lmtNqT6u2TW8zfuumYTyiyxG4Y8DS5ahSmrX1GMXXP3TPxav4lOFUWH8zUN9ufC8+fK3/JrrOOluUQUy5Ji43Yom0PD3VCq1YZUX5fMmgwCU29uB6DqTUb42ecSK+7+bimeWv+WYuzqEbOwN6ORThWFR+0S2WAYhcC0ge38hgN/m++54ZmIKHhJvXE7lM2h4W4o1WpDqvNN85nl26ovlwkgf28pFhcUu0JUTHfTlhKPbJiPURs+cA0dr2FGz7tn4lCdBjoWFj6J8IKSTcqAZoKCXX4lIqLQJUVICuXUWbgn1bQ86ea8dsIzJFltMj7uVpMST66fgxHfL3UN/XFGPfS+43/4My1Dx8K0I0T4AdXzMmS1PXHBLr8SEVHokuJ0WyinzsI9qdattfrMiNp4XmExOk9Zh+ZjVqLzlHWqXbHjrb8RAAhpx39XvYI9z/d1BaRd9TLR7uH56PjAewkTkEwGodkMnnMmyLnMWlxmgUTVnqNurRtU+7l04oZnIiJtJcVMUiibQ8PdULp+R0lA44nYcdhot+HFFS/ixp++cI1tObslbhn8LMprpupYmTZMRoG0Gik4arGiUboZFacqNTs56JwJ8tbKYf2OEkzu3zZhTrcREcWypAhJQPCX1Yb6NU6B7kny9mbo7H/kDGnxwGSz4rWl/8U1u753jX3T5BLcedN4nDTV1LEy7aiFkeZjVmry3AJVF9f6+vkJ5+eSiIgClzQhKdoC3ZPk7c3QOaPkrZFkLKllPYF3F05Ax/0/usY+Pb8j/pU9BlZj7DewDJS3k2P+9gkFSqJq9lDr7u1ERBS8pNiTpIdA9zR5e9MzChHzASntZAWWv/MIdrx4kysgLWnTDS1yPsLwAU/FbUDKSDUFtR/N22vt3kk7EJluPwuR6N5ORETB4UxShLjvaXLuHXFfRnN+3lvH4VgOSHUtfyPv/dFofuSQa+z9Djfg6Z73QYr4zt3O+9KAwPejedu/BiDg2UDPAMQmi0RE+ou7ZpKhXC8Sje/vflWEk1EIdDovA5v3Ha0Wgtzv5VJ7Ts/nigUNjh/Bx28/hAYVZa6x1zsOwJSr73CcgY9D0we1j+jPk+dr2611A6zfUcJN10REMcRbM8m4Cklq3ac9A0ckefv+Ay7LVDR0DIS/zsi+Om1H2znHSrD2zfuQaj3pGnvhH8PwylWDdawqfOxOTUREQIJ03PZ1EiyUC0LVZg/cP+e8oLasouqot9r3n79pv+sOrUAVl1nQeco6rzMIzrEJy7b5vYvNZBAwGQUqrPagavCn6ZGD+GLWCMXYxO734K3LszX9Pnrwtb9H79lKIiKKDXEVkrS46sNXXyJAuYfEPZz4WvoKNiC5P+fYJVuRv7cU63eUVHtTdu1bWrgFVi8XsplNBkzuf4njcYu2wGoLf2bwgpI9WDPnQcXYE9c9hNx2vcJ+7liQkWrC+L5tVINPIvatIiKi0MTVcpsWl8b6eg4gtM7Wzr0lWnK+kfvam9S5RT3s+cuCg2UWGDSooe2hX7D8vVGKsYf75mDZRVeH9bxaSzeb0KfdOVix5ZAryLoHn7zCYsUMnPPKkED2/vj7GeMsExFR4kmI5TZvJ8GCORat1cWz7t//0iZ1sWFXaUhf782RCitG5hb5fIz79wwnIF2+/0cs/GCMYuye/k/hs5YdQ37OSCqzWLF+Rwkm9FOfDQKAk5VVS49SVv2c+As0vn4+8gqLFbN6xWUWjMwtwsjcIm6+JiJKQHEVkrQ4Fu2vSZ+/maR0swlpNVOqnUSLR//4bTPeX/C0YmzooEnY0Ky9PgUFwdcyWCh715wzRN6iZqN0MyYs2+Z12ZPLckREiSeuQhIQ3lUhgO/ZqPy9pZi7cZ/XrzWbjKqzF6P8zPjEmmt//hazlj6rGBsw9HkUnHuRThWFxlvwCXa20N9JQufPh7+ZvVAOERARUewKOCQJIYwA8gEUSyn7RK6kyFKbjerWuoHfvkS+llO0upYi0rK3rcf0FdMUY71vn45tZ5+vU0XhUws+wV7poTbz5OT+uvsLSd7qISKi+BTMTNIjAH4CUCdCtUSN+2xUIP2IBOBzY7ja7FQsuaXoE/x39auKsWvunolf6zfRqSLtqAWfYPeueQs2nq97RqoJRyp8t2Pg3WpERIkjoJAkhDgXQG8AzwIYHdGKoszXLIKTvzc+Z+AKZKYhmu75bgnGrZ+jGOsyYjb2ZZyjU0WA0SBg87KvJ1jegk+we9cCnXka37eNzzYLvFuNiCixBDqTNB3A4wBqR64UffhbHgn0jc/fckxmuhnNzjRrfgquGikxcsMHGLlhvmvoWI1UXHv3TPxep35kv7cfnkuW4XQVNwrhs9N6MHvXAp158gxf6akmSAkctVjZDoCIKAH5DUlCiD4ADkspC4QQXX08bgSAEQDQpEn8LOP42k8U7LFub/2SjEK4lm3G5W31uTk8ZFLi3+vfwvDv81xDv59RD73vmIG/0tK1/35uBAAJx59XaflJWFQ6f6ebTdWWLD0vAXY+j5PJKGCzSXg+m8koMPWmdpoFkmBmnsI9OEBERPHDbzNJIcRkALcCqARQC449SUuklMO8fU0kL7jVmpb3wXkLQMM6NcGk7LY+v2eohLTjv6tewZAf1rjGfq13Lvrf+gKO1Toj6Odz3kW38odDrv037iHIObvi61oXzw7hJoPA1Jv9hxq1Ro2A8moWX92yiYiIQqHJBbenZ5Ie83e6LZ5CEqDtXV3j8ra67nIzCoEhHRsrApLa9/RctnG/Kd4bo92G6ctfQN8dX7nGis5piaGDnoWxTm2Un7IH3WBSq4aI7EpNRETxhCEpUZw8CfTvD3z8cdVY9+7AihWAmSeriIiIgqXJtSRSys8BfK5RTRSMigqgVy/g66+rxrKzgdxcoEYN3coiIiJKVAa9CyA/jh0DOnQA0tKqAtKttwKVlcDSpQxIREREEcKQFKv++gto0QKoWxcoKnKM/etfgM0GvPceYDTqWh4REVGiY0iKNb//DjRsCNSvD+ze7RgbMwaw24FXXwUMfMmIiIiiIe4uuE1Y+/YBrVoBJ05UjU2cCIwbp19NRERESYwhSW+//AJccIFybPp04JFHdCmHiIiIHBiS9PLjj0Bbj/5Jb70F3HWXPvUQERGRAkNStH3/PXDFFcqxDz8EBg3Spx4iIiJSxZAULV9+CVx9tXJs+XKgj8++nERERKQThqRIW70auO465dhnnwE9euhTDxEREQWEISlSliwBBgxQjn3zDXDllfrUQ0REREFh0x2tvf8+IIQyIG3eDEjJgERERBRHGJK08vrrjnB0221VY9u3O8JRhw761UVEREQhYUgK19SpjnB0//2Ojw0GYNcuRzi68EJ9ayMiIqKQMSSFQkrg6acd4ejxxx1jdesCBw447lY77zx96yMiIqKwceN2MKQERo92dMR2OvdcoKDAcd8aERERJQyGpEDY7cDw4cCcOVVjF10EbNgApKfrVhYRERFFDkOSL5WVwNChwIIFVWNXXAGsXQuccYZ+dREREVHEMSSpOXkSyM4GVq2qGrvmGkeH7Fq1dCuLiIiIoocbt92VlwP/93+OIOQMSP37A6dOAZ9+yoBERESURDiTBABHjwJdugA//FA1dtttjj1IRqN+dREREZFuknsm6c8/gebNHZuvnQHpwQcdx/jffZcBiYiIKIklZ0g6dAioXx9o0ADYs8cxNnas4xTbyy87GkISERFRUkuu5ba9e4ELLnDsMXJ69lngySf1q4mIiIhiUnKEpJ9/Blq1Uo7NmAE89JA+9RAREVHMS+yQ9MMPQLt2yrE5c4A779SnHiIiIoobiRmSvvsO6NhROZabCwwcqE89REREFHcSKyR98QXQtatybMUKoHdvXcohIiKi+JUYIWnVKuD665Vja9cC3bvrUw8RERHFvfgOSYsXAzfdpBz79lugUyd96iEiIqKEEZ8hae1ax11q7goLgfbtdSmHiIiIEk98hqSJE6v++aefgNat9auFiIiIElJ8hqSVKx0NITMy9K6EiIiIElR8hqS0NMdfRERERBHCS8qIiIiIVDAkEREREalgSCIiIiJSwZBEREREpIIhiYiIiEgFQxIRERGRCoYkIiIiIhUMSUREREQqGJKIiIiIVDAkEREREakQUkrtn1SIEgB7NX9iCkZ9AH/qXQR5xdcndvG1iV18bWJXvL82TaWUDTwHIxKSSH9CiHwpZZbedZA6vj6xi69N7OJrE7sS9bXhchsRERGRCoYkIiIiIhUMSYlrlt4FkE98fWIXX5vYxdcmdiXka8M9SUREREQqOJNEREREpIIhKUEJIYxCiEIhxAq9a6EqQog9QoitQogiIUS+3vVQFSFEuhBikRBihxDiJyHElXrXRIAQotXp/16cfx0TQozUuy5yEEKMEkJsE0L8KISYL4SopXdNWuJyW4ISQowGkAWgjpSyj971kIMQYg+ALCllPPcTSUhCiHcBfCWlfFMIUQNAqpSyTOeyyI0QwgigGEBHKSV78elMCJEJ4GsAF0kpLUKIBQA+llK+o29l2uFMUgISQpwLoDeAN/WuhSgeCCHqAOgC4C0AkFKeYkCKST0A7GJAiikpAMxCiBQAqQAO6lyPphiSEtN0AI8DsOtcB1UnAawRQhQIIUboXQy5nAegBMDbp5ep3xRCpOldFFUzGMB8vYsgByllMYAXAOwDcAjAUSnlGn2r0hZDUoIRQvQBcFhKWaB3LaSqs5TyUgDXA3hACNFF74IIgOO34UsBvCal7ACgHMAYfUsid6eXQPsBWKh3LeQghMgAcCOA5gAaAUgTQgzTtyptMSQlns4A+p3e+/IhgO5CiLn6lkROUsqDp/9+GMBSAFfoWxGddgDAASnlptMfL4IjNFHsuB7AZinlH3oXQi7XAPhNSlkipbQCWALgKp1r0hRDUoKRUo6VUp4rpWwGx9T0OillQiX7eCWESBNC1Hb+M4BrAfyob1UEAFLK3wHsF0K0Oj3UA8B2HUui6oaAS22xZh+ATkKIVCGEgOO/m590rklTKXoXQJREzgKw1PH/EqQA+EBKuUrfksjNQwDmnV7W2Q3gTp3rodOEEKkAegK4V+9aqIqUcpMQYhGAzQAqARQiwTpvswUAERERkQoutxERERGpYEgiIiIiUsGQRERERKSCIYmIiIhIBUMSERERkQqGJCIiIiIVDElEREREKhiSiIiIiFT8P4pXt3BejhoxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e526cdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.560682</td>\n",
       "      <td>5.536685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.886104</td>\n",
       "      <td>5.975955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.700480</td>\n",
       "      <td>4.924685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.645447</td>\n",
       "      <td>5.396454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.356709</td>\n",
       "      <td>4.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.394449</td>\n",
       "      <td>4.334312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.545177</td>\n",
       "      <td>5.779590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.919981</td>\n",
       "      <td>4.870454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.298317</td>\n",
       "      <td>5.362316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.337538</td>\n",
       "      <td>5.428463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.208590</td>\n",
       "      <td>6.170928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.198497</td>\n",
       "      <td>5.179551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.068904</td>\n",
       "      <td>5.184796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>4.620937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.181784</td>\n",
       "      <td>5.165114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.308268</td>\n",
       "      <td>5.263903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.176150</td>\n",
       "      <td>5.195438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.343805</td>\n",
       "      <td>4.357599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.056784</td>\n",
       "      <td>5.870066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.793014</td>\n",
       "      <td>5.671600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "0   5.560682   5.536685\n",
       "1   5.886104   5.975955\n",
       "2   4.700480   4.924685\n",
       "3   5.645447   5.396454\n",
       "4   4.356709   4.581600\n",
       "5   4.394449   4.334312\n",
       "6   5.545177   5.779590\n",
       "7   4.919981   4.870454\n",
       "8   5.298317   5.362316\n",
       "9   5.337538   5.428463\n",
       "10  6.208590   6.170928\n",
       "11  5.198497   5.179551\n",
       "12  5.068904   5.184796\n",
       "13  4.595120   4.620937\n",
       "14  5.181784   5.165114\n",
       "15  5.308268   5.263903\n",
       "16  5.176150   5.195438\n",
       "17  4.343805   4.357599\n",
       "18  6.056784   5.870066\n",
       "19  5.793014   5.671600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = []\n",
    "for pred in y_pred:\n",
    "  y_pred_2.append(pred[0])\n",
    "\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_2})\n",
    "df1 = df.head(20)\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
